# MapReduce

> [paper链接](https://pdos.csail.mit.edu/6.824/labs/lab-mr.html)

## 简介

《MapReduce: Simplified Data Processing on Large Clusters》由Jeffrey Dean和Sanjay Ghemawat撰写，介绍了一种简化大规模数据集处理的编程模型和实现。用户指定一个map函数，用于处理键/值对并生成一组中间键/值对；一个reduce函数，则将所有相同中间键的值合并。

**主要内容概述如下**：

1. **编程模型**：
   - 用户定义map和reduce函数。
   - map函数处理输入键/值对并生成中间键/值对。
   - reduce函数处理中间键及其关联的一组值，并生成最终的输出值。
2. **自动并行化和执行**：
   - 程序在一个由商品机器组成的大型集群上自动并行化和执行。
   - 运行时系统处理输入数据的分区、任务调度、故障处理和机器间通信。
3. **实现**：
   - MapReduce在Google的一个大规模商品机器集群上运行，非常具有可扩展性。
   - 通常处理数TB的数据，分布在数千台机器上。
   - 提供简单且强大的接口，使非并行和分布式系统经验的程序员也能轻松利用大规模分布式系统的资源。
4. **实际应用**：
   - 作者和Google的许多人员已实现数百个特殊用途的计算，用于处理大量原始数据（如抓取的文档、网页请求日志等）。
   - 这些计算的输入数据通常非常庞大，必须分布在数百到数千台机器上，以在合理的时间内完成。
5. **优点**：
   - 简化了并行化、故障容错、数据分布和负载均衡的复杂性。
   - 使用函数式编程模型，用户指定的map和reduce操作使得大规模计算容易并行化，并使用重执行作为主要故障容错机制。
6. **应用示例**：
   - 文章列举了多个简单示例，如分布式grep、URL访问频率统计、反向网页链接图、每主机词汇表、倒排索引、分布式排序等，展示了MapReduce模型的广泛适用性。

## Lab1

> 在本实验中，您将构建一个MapReduce系统。你将实现一个工作进程，该进程调用应用程序 Map 和 Reduce 函数并处理读取和写入文件，以及一个将任务分发给工作线程并处理失败工作线程的协调器进程。您将构建类似于MapReduce论文的内容。
>
> map任务：读取文件并均匀分配至对应数量的reduce所需要读取中间文件中
>
> reduce任务：读取中间文件，对key进行sort，并对相同key值的value进行处理，最后再输出

[lab链接](https://pdos.csail.mit.edu/6.824/labs/lab-mr.html)

### Code

#### rpc.go

> 设置消息参数类型
>
> 包括常量：TaskCompletedStatus(任务状态信息)、TaskType(worker执行任务类型)，类：MessageSend(任务状态变更)、MessageReply(回复worker消息信息)

```go
// 对于任务完成情况的状态消息   成功或者失败
type TaskCompletedStatus int
const (
	MapTaskCompleted = iota // 从零开始，下面几个变量依次加一
	MapTaskFailed
	ReduceTaskCompleted
	ReduceTaskFailed
)

// 对于给worker的任务类型消息     Map任务或者Reduce任务  等待任务或者退出任务
type TaskType int
const (
	MapTask = iota
	ReduceTask
	Wait
	Exit
)

// 状态变更消息
type MessageSend struct {
	TaskID              int                 // 任务 id
	TaskCompletedStatus TaskCompletedStatus // 任务完成状态
}

// 任务回复配置消息
type MessageReply struct {
	TaskID   int      // 任务id
	TaskType TaskType // 任务类型
	TaskFile string   // 任务文件
	NReduce  int      // reduce任务数量
	NMap     int      // map任务数量
}
```

#### coordinator.go

> 调度者
>
> 负责分配任务给worker，并统计worker的任务执行情况，使用TaskStatus去标记任务状态，有mapTasks和reduceTasks数组
>
> 在初始化时，根据输入文件数量去决定NMap的数量，NReduce->worker的数量，由用户输入决定
>
> 内部有一把Mutex锁，确保任务状态信息正确变更
>
> 先确保map任务全部执行完毕再去执行reduce任务

```go
// 任务状态  未分配  已分配  完成  失败
type TaskStatus int
const (
	Unassigned = iota
	Assigned
	Completed
	Failed
)

// 任务信息 任务状态  任务文件  时间戳(防止任务超时)
type TaskInfo struct {
	TaskStatus TaskStatus // task status
	TaskFile   string     // task file
	TimeStamp  time.Time  // time stamp, indicating the running time of the task
}

// 调度器
type Coordinator struct {
	// Your definitions here.
	NMap                   int        // map任务数量   由文件数量决定
	NReduce                int        // reduce任务数量  由用户输入决定
	MapTasks               []TaskInfo // map任务
	ReduceTasks            []TaskInfo // reduce任务
	AllMapTaskCompleted    bool       // 是否全部的map任务完成
	AllReduceTaskCompleted bool       // 是否全部的reduce任务完成
	Mutex                  sync.Mutex // 锁，用于保护共享数据，确保任务的状态正确变更

}

// 根据文件数组初始化任务，由于reduce需要中间文件，所以file暂时为空
func (c *Coordinator) InitTask(file []string) {
	for idx := range file {
		c.MapTasks[idx] = TaskInfo{
			TaskFile:   file[idx],
			TaskStatus: Unassigned,
			TimeStamp:  time.Now(),
		}
	}
	for idx := range c.ReduceTasks {
		c.ReduceTasks[idx] = TaskInfo{
			TaskStatus: Unassigned,
		}
	}
}
// 开启一个线程监听worker的请求
func (c *Coordinator) server() {
	rpc.Register(c)
	rpc.HandleHTTP()
	//l, e := net.Listen("tcp", ":1234")
	sockname := coordinatorSock()
	os.Remove(sockname)
	l, e := net.Listen("unix", sockname)
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go http.Serve(l, nil)
}

// 创建调度者
func MakeCoordinator(files []string, nReduce int) *Coordinator {
	c := Coordinator{
		NReduce:                nReduce,
		NMap:                   len(files),
		MapTasks:               make([]TaskInfo, len(files)),
		ReduceTasks:            make([]TaskInfo, nReduce),
		AllMapTaskCompleted:    false,
		AllReduceTaskCompleted: false,
		Mutex:                  sync.Mutex{},
	}
	c.InitTask(files)
	c.server()
	return &c
}

// 接受MessageSend(任务状态信息)，更新自身管理任务状态的信息
func (c *Coordinator) ReportTask(args *MessageSend, reply *MessageReply) error {
	c.Mutex.Lock()
	defer c.Mutex.Unlock()
	if args.TaskCompletedStatus == MapTaskCompleted {
		c.MapTasks[args.TaskID].TaskStatus = Completed
		return nil
	} else if args.TaskCompletedStatus == MapTaskFailed {
		c.MapTasks[args.TaskID].TaskStatus = Failed
		return nil
	} else if args.TaskCompletedStatus == ReduceTaskCompleted {
		c.ReduceTasks[args.TaskID].TaskStatus = Completed
		return nil
	} else if args.TaskCompletedStatus == ReduceTaskFailed {
		c.ReduceTasks[args.TaskID].TaskStatus = Failed
		return nil
	}
	return nil
}

// worker请求任务的RPC处理函数
func (c *Coordinator) RequestTask(args *MessageSend, reply *MessageReply) error {
	// lock  一把大锁保平安
	c.Mutex.Lock()
    
    // 不论什么情况(正常完成或者出现异常) 最后都会释放锁
	defer c.Mutex.Unlock()

	// 先考虑分配map任务
	if !c.AllMapTaskCompleted {
		// 对map任务完成的数量进行计数
		NMapTaskCompleted := 0
		for idx, taskInfo := range c.MapTasks {

			// 任务未分配或者任务失败或者任务已分配但是超时
			if taskInfo.TaskStatus == Unassigned || taskInfo.TaskStatus == Failed ||
				(taskInfo.TaskStatus == Assigned && time.Since(taskInfo.TimeStamp) > 10*time.Second) {
				reply.TaskFile = taskInfo.TaskFile
				reply.TaskID = idx
				reply.TaskType = MapTask
				reply.NReduce = c.NReduce
				reply.NMap = c.NMap
				c.MapTasks[idx].TaskStatus = Assigned  // 标记该任务已分配
				c.MapTasks[idx].TimeStamp = time.Now() // 更新时间戳
				return nil
			} else if taskInfo.TaskStatus == Completed {
				// 任务已完成，计数加1
				NMapTaskCompleted++
			}
		}
		// 检查是否所有map任务都已完成
		if NMapTaskCompleted == len(c.MapTasks) {
			c.AllMapTaskCompleted = true
		} else {
			// 有任务未完成且未超时，让worker等待
			reply.TaskType = Wait
			return nil
		}
	}

	// map任务已完成，开始分配reduce任务
	if !c.AllReduceTaskCompleted {
		// 对reduce任务完成的数量进行计数
		NReduceTaskCompleted := 0
		for idx, taskInfo := range c.ReduceTasks {
			if taskInfo.TaskStatus == Unassigned || taskInfo.TaskStatus == Failed ||
				(taskInfo.TaskStatus == Assigned && time.Since(taskInfo.TimeStamp) > 10*time.Second) {
				reply.TaskID = idx
				reply.TaskType = ReduceTask
				reply.NReduce = c.NReduce
				reply.NMap = c.NMap
				c.ReduceTasks[idx].TaskStatus = Assigned  // 标记该任务已分配
				c.ReduceTasks[idx].TimeStamp = time.Now() // 更新时间戳
				return nil
			} else if taskInfo.TaskStatus == Completed {
				NReduceTaskCompleted++
			}
		}
		// 检查是否所有reduce任务都已完成
		if NReduceTaskCompleted == len(c.ReduceTasks) {
			c.AllReduceTaskCompleted = true
		} else {

			// 有任务未完成且未超时，让worker等待
			reply.TaskType = Wait
			return nil
		}
	}

	// 所有任务都已完成
	reply.TaskType = Exit
	return nil
}
```

#### worker.go

> 工人
>
> 轮训向coordinator请求任务，根据MessageReply去执行对应的任务
>
> 处理mapTask：根据分配的文件，去读取key-value，并对key取hash，分配到对应的reduce任务的中间文件中，发送MessageSend标记任务完成
>
> 处理reduceTask：根据文件名列表，"mr-0-taskId"~"mr-NMap-taskId"，去取出该reduce任务对应的key-value，统计相同key值的所有value，再调用reducef生成最终输出，发送MessageSend标记任务完成

```go
// KeyValue结构体.
type KeyValue struct {
	Key   string
	Value string
}

// 用key的hash值 % NReduce去选择reduce
func ihash(key string) int {
	h := fnv.New32a()
	h.Write([]byte(key))
	return int(h.Sum32() & 0x7fffffff)
}

// 工人线程执行函数
func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) {

	// 轮询请求任务
	for {
		args := MessageSend{}
        
        // 请求返回值存储
		reply := MessageReply{}

		// rpc远程调用请求任务
		call("Coordinator.RequestTask", &args, &reply)

		// 根据任务类型处理任务
		switch reply.TaskType {
		case MapTask:
			HandleMapTask(&reply, mapf)
		case ReduceTask:
			HandleReduceTask(&reply, reducef)
		case Wait:
			time.Sleep(1 * time.Second)
		case Exit:
			os.Exit(0)
		default:
			time.Sleep(1 * time.Second)
		}
	}
}

// MapTask处理函数
func HandleMapTask(reply *MessageReply, mapf func(string, string) []KeyValue) {
	// 打开任务文件
	file, err := os.Open(reply.TaskFile)
	if err != nil {
		log.Fatalf("cannot open %v", reply.TaskFile)
		return
	}
	// 读取文件内容
	content, err := io.ReadAll(file)
	if err != nil {
		log.Fatalf("cannot read %v", reply.TaskFile)
		return
	}
	file.Close()

	// 调用map函数读取key value
	kva := mapf(reply.TaskFile, string(content))
	// 生成中间文件键值对数组
	intermediate := make([][]KeyValue, reply.NReduce)
	for _, kv := range kva {

		// 根据key的hash值对reduce任务进行分配
		r := ihash(kv.Key) % reply.NReduce
		intermediate[r] = append(intermediate[r], kv)
	}

	// 写入文件
	for r, kva := range intermediate {
        // 不能统一一个reduce的中间文件，会导致多线程编辑文件冲突
		oname := fmt.Sprintf("mr-%v-%v", reply.TaskID, r)
		ofile, err := os.CreateTemp("", oname)
		if err != nil {
			log.Fatalf("cannot create tempfile %v", oname)
		}

		// 编辑器
		enc := json.NewEncoder(ofile)
		for _, kv := range kva {
			// 写入文件
			enc.Encode(kv)
		}
		ofile.Close()
		// 重命名文件，
		os.Rename(ofile.Name(), oname)
	}

	// 发送任务完成消息
	args := MessageSend{
		TaskID:              reply.TaskID,
		TaskCompletedStatus: MapTaskCompleted,
	}
	call("Coordinator.ReportTask", &args, &MessageReply{})
}

// 获得中间文件名数组，以reduceid为索引，获得每个map任务所对应的reduce编号的数据
func generateFileName(r int, NMap int) []string {
	var fileName []string
	for TaskID := 0; TaskID < NMap; TaskID++ {
		fileName = append(fileName, fmt.Sprintf("mr-%d-%d", TaskID, r))
	}
	return fileName
}

// ReduceTask处理函数
func HandleReduceTask(reply *MessageReply, reducef func(string, []string) string) {
	// 读取中间文件
	var intermediate []KeyValue
	// 生成中间文件名数组
	intermediateFiles := generateFileName(reply.TaskID, reply.NMap)
	// 读取中间文件
	for _, filename := range intermediateFiles {
		file, err := os.Open(filename)
		if err != nil {
			log.Fatalf("cannot open %v", filename)
			return
		}
		// 读取文件内容
		dec := json.NewDecoder(file)
		for {
			kv := KeyValue{}
			if err := dec.Decode(&kv); err == io.EOF {
				break
			}
			intermediate = append(intermediate, kv)
		}
		file.Close()
	}

	// 对key进行排序
	sort.Slice(intermediate, func(i, j int) bool {
		return intermediate[i].Key < intermediate[j].Key
	})

	// 生成输出文件
	oname := fmt.Sprintf("mr-out-%v", reply.TaskID)
	ofile, err := os.Create(oname)
	if err != nil {
		log.Fatalf("cannot create %v", oname)
		return
	}
	for i := 0; i < len(intermediate); {
		j := i + 1

		// 处理相同key的value
		for j < len(intermediate) && intermediate[j].Key == intermediate[i].Key {
			j++
		}
		var values []string
		for k := i; k < j; k++ {
			values = append(values, intermediate[k].Value)
		}

		// 调用reduce函数 生成输出
		output := reducef(intermediate[i].Key, values)

		// 写入文件 key value
		fmt.Fprintf(ofile, "%v %v\n", intermediate[i].Key, output)

		i = j
	}
	ofile.Close()
	// 重命名文件 保证文件名正确
	os.Rename(ofile.Name(), oname)

	// 发送任务完成消息
	args := MessageSend{
		TaskID:              reply.TaskID,
		TaskCompletedStatus: ReduceTaskCompleted,
	}
	call("Coordinator.ReportTask", &args, &MessageReply{})
}

// 向coordinator发送rpc请求，等待响应，通常返回true
// 如果有异常返回false
func call(rpcname string, args interface{}, reply interface{}) bool {
	// c, err := rpc.DialHTTP("tcp", "127.0.0.1"+":1234")
   	// 链接socket
	sockname := coordinatorSock()
	c, err := rpc.DialHTTP("unix", sockname)
	if err != nil {
		log.Fatal("dialing:", err)
	}
	defer c.Close()

	err = c.Call(rpcname, args, reply)
	if err == nil {
		return true
	}

	fmt.Println(err)
	return false
}
```

# GFS

> [paper链接](https://pdos.csail.mit.edu/6.824/papers/gfs.pdf)

## 简介

- 更多去执行追加操作，而不是去编辑，覆盖

- 客户端不与主服务器进行读写，从主服务器知道应该与那个块服务器联系，存储该服务器信息后再进行文件的读写

- 块大小为64MB

- 客户端将文件名和偏移量(文件大小)转成文件块索引，向主服务器发送请求获得块句柄(块服务器的位置)和副本，用文件名哦和块索引作为键来存储

- 主服务器在启动的时候才会去轮训各个块的信息，此后会定期请求数据

- 恢复时，master读取 Checkpoint 文件并重演之后的日志文件即可。Checkpoint 文件以压缩 B-树形式存储，可以直接映射到内存，在用于命名空间查询时无需额外的解析，提高了恢复速度和系统可用性。
- 尽量减少master服务器的压力，在进行数据的更改时，需要更改所有副本，此时先搞一个主副本，将这件事交给主副本与客户端进行沟通，只有主副本失效时客户端再去向master服务器再申请一个
- 主副本内部分存有lease(租约)，更新数据的副本顺序，所有副本按照这个租约里的顺序进行更改数据
- 垃圾回收：当文件被删除时，文件并不会立即删除，而是被重命名带时间戳的名字，当系统开始文件和chunk级别的常规垃圾回收时，会检测删除时间是否到期，到期后才会进行删除
- 在 GFS 集群中，高可用性的策略主要包括快速恢复和复制
- 每个 Chunkserver使用 checksum 来检查保存的数据是否损坏当， chunkserver空闲时，会扫描和校验每个不活动 chunk 的内容，以发现很少被读取的 chunk 是否完整。一旦发现数据损坏，master 可以创建新的正确副本并删除损坏的副本，避免非活动的损坏 chunk 误导 master，使其认为副本数量足够。

[参考：论文阅读博客笔记](https://pursuit.blog.csdn.net/article/details/139270419?spm=1001.2014.3001.5502)

# Go-RPC

> 远程过程调用（RPC）是分布式系统中的关键技术之一，它使得客户端和服务器之间的通信变得简单而直观。在分布式系统中，不同的节点可能分布在不同的物理机器上，RPC允许这些节点之间进行远程通信，就像调用本地函数一样，无需了解底层的网络协议细节。

## 简介

在Go中，实现RPC需要定义请求和回复的结构体，并使用Go的RPC库来处理通信。下面是一个示例，展示了如何在Go中实现一个简单的键值存储服务器（key/value storage server），并使用RPC进行通信。

- **请求回复结构体**

  在键值存储服务器的示例中，我们定义了用于Put和Get操作的请求和回复结构体：

  ```go
  type PutArgs struct {
  	Key   string
  	Value string
  }
  
  type PutReply struct {
  }
  
  type GetArgs struct {
  	Key string
  }
  
  type GetReply struct {
  	Value string
  }
  
  ```

- **服务器端（Server）**

  在服务器端，首先需要定义一个对象，并在该对象上注册处理函数作为RPC处理程序。这些处理函数将处理客户端发送的RPC请求。服务器接受TCP连接并将其传递给RPC库。RPC库负责读取每个请求，并为每个请求创建一个新的Goroutine进行处理。处理函数会读取请求参数，并根据请求调用相应的方法。处理完请求后，服务器将回复信息进行序列化，并通过TCP连接发送回客户端。服务器端的处理函数必须使用锁进行同步，因为RPC库为每个请求创建了一个新的Goroutine。处理函数需要读取请求参数并修改回复信息，因此需要确保并发访问的安全性。

  ```go
  type KV struct {
  	mu   sync.Mutex // 互斥锁，保护数据并发访问
  	data map[string]string
  }
  
  func server() {
  	kv := &KV{data: map[string]string{}} // 创建键值存储服务器实例
  	rpcs := rpc.NewServer()              // 创建一个 RPC 服务器
  	rpcs.Register(kv)                    // 注册 kv 为 RPC 服务器的服务对象
  	l, e := net.Listen("tcp", ":1234")   // 监听 TCP 端口 1234
  	if e != nil {
  		log.Fatal("listen error:", e)
  	}
  	go func() { // 启动一个协程来处理客户端连接
  		for {
  			conn, err := l.Accept() // 接受客户端连接
  			if err == nil {
  				go rpcs.ServeConn(conn) // 启动一个协程来为客户端提供服务
  			} else {
  				break
  			}
  		}
  		l.Close() // 关闭监听器
  	}()
  }
  
  // Get 方法用于处理客户端发送的 Get 请求，获取指定键的值。
  func (kv *KV) Get(args *GetArgs, reply *GetReply) error {
  	kv.mu.Lock()
  	defer kv.mu.Unlock()
  
  	reply.Value = kv.data[args.Key]
  
  	return nil
  }
  
  // Put 方法用于处理客户端发送的 Put 请求，存储键值对。
  func (kv *KV) Put(args *PutArgs, reply *PutReply) error {
  	kv.mu.Lock()
  	defer kv.mu.Unlock()
  
  	kv.data[args.Key] = args.Value
  
  	return nil
  }
  
  ```

- **客户端（Client）**

  在客户端，首先需要使用Dial函数建立与服务器的TCP连接。然后，客户端需要定义RPC请求的参数结构体和回复结构体，并实现对应的处理函数。客户端通过调用Call函数发起RPC调用，指定连接、函数名称、参数以及存放回复的位置。RPC库负责对参数进行序列化，并将请求发送给服务器。然后，客户端等待并接收服务器的回复，并将回复反序列化为指定的回复结构体。Call函数的返回值指示是否成功接收到了回复，通常还包括服务级别的错误信息。

  ```go
  // connect 函数用于与键值存储服务器建立连接，并返回一个 RPC 客户端对象。
  func connect() *rpc.Client {
  	client, err := rpc.Dial("tcp", ":1234") // 使用 TCP 协议连接服务器
  	if err != nil {
  		log.Fatal("dialing:", err) // 如果连接失败，则记录错误并终止程序
  	}
  	return client
  }
  
  func get(key string) string {
  	client := connect()                         // 建立连接
  	args := GetArgs{key}                        // 构造 Get 请求的参数
  	reply := GetReply{}                         // 准备接收服务器的响应
  	err := client.Call("KV.Get", &args, &reply) // 调用远程方法 Get，并传递参数 args，将响应写入 reply
  	if err != nil {
  		log.Fatal("error:", err)
  	}
  	client.Close()     // 关闭连接
  	return reply.Value // 返回服务器返回的值
  }
  
  // put 函数用于向键值存储服务器发送 Put 请求，存储键值对。
  func put(key string, val string) {
  	client := connect()
  	args := PutArgs{key, val}
  	reply := PutReply{}
  	err := client.Call("KV.Put", &args, &reply)
  	if err != nil {
  		log.Fatal("error:", err)
  	}
  	client.Close()
  }
  
  ```

  


## Lab2

> 在本实验中，您将为一台计算机构建一个键/值服务器，以确保每个操作在网络故障的情况下只执行一次，并且操作是可线性化的。稍后的实验室将复制像这样的服务器来处理服务器崩溃。

[lab链接](https://pdos.csail.mit.edu/6.824/labs/lab-kvsrv.html)

### common.go

> 客户端和服务端共有的消息类型

```go
// 消息类型
type MessageType int

const (
    // pur|append
	Modify = iota
    // 模拟任务完成，删除数据，防止数据累积
	Report
)

// Put 或 Append
type PutAppendArgs struct {
	Key   string
	Value string

	MessageType MessageType // 修改或者报告
	MessageID   int64       // 消息id
}

// 返回旧值
type PutAppendReply struct {
	Value string
}

// get - key
type GetArgs struct {
	Key string
	// You'll have to add definitions here.
}

// 返回key的对应值
type GetReply struct {
	Value string
}
```

### server.go

> 服务器必须安排应用程序对 `Clerk` Get/Put/Append 方法的调用是可线性化的。如果客户端请求不是并发的，则每个客户端 Get/Put/Append 调用都应观察对前面调用序列所隐含的状态的修改。对于并发调用，返回值和最终状态必须与操作按特定顺序一次执行一个操作相同。如果调用在时间上重叠，则调用是并发的：例如，如果客户端 X 调用 `Clerk.Put()` ，客户端 Y 调用 `Clerk.Append()` ，然后客户端 X 的调用返回。呼叫必须观察在呼叫开始之前已完成的所有呼叫的效果

```go
type KVServer struct {
    // 上锁，确保数据的正确性
	mu sync.Mutex

    // 存储数据
	data   map[string]string
    
    // 存储请求记录
	record sync.Map
}


func (kv *KVServer) Get(args *GetArgs, reply *GetReply) {
	// 通过上锁确保数据的正确性
	kv.mu.Lock()
	defer kv.mu.Unlock()
	reply.Value = kv.data[args.Key]
}

func (kv *KVServer) Put(args *PutAppendArgs, reply *PutAppendReply) {
	// 是否是任务请求完成
	if args.MessageType == Report {
        // 删除任务id对应的记录
		kv.record.Delete(args.MessageID)
	}
    
    // 判断是否有记录过此任务ID
	res, ok := kv.record.Load(args.MessageID)
	if ok {
		reply.Value = res.(string) // 重复请求，返回之前的结果
		return
	}
    
    // 上锁，加数据
	kv.mu.Lock()
    
    // 保存旧值
	old := kv.data[args.Key]
	kv.data[args.Key] = args.Value
	reply.Value = old
	kv.mu.Unlock()

	kv.record.Store(args.MessageID, old) // 记录请求

}

func (kv *KVServer) Append(args *PutAppendArgs, reply *PutAppendReply) {
	// 是否是任务请求完成
	if args.MessageType == Report {
        // 删除任务id对应的记录
		kv.record.Delete(args.MessageID)
	}
    // 判断是否有记录过此任务ID
	res, ok := kv.record.Load(args.MessageID)
	if ok {
		reply.Value = res.(string) // 重复请求，返回之前的结果
		return
	}
    // 上锁，加数据
	kv.mu.Lock()
    
    // 保存旧值
	old := kv.data[args.Key]
	kv.data[args.Key] = old + args.Value
	reply.Value = old
	kv.mu.Unlock()

	kv.record.Store(args.MessageID, old) // 记录请求
}

func StartKVServer() *KVServer {
    
    // 创建服务
	kv := new(KVServer)
    
    kv.data = make(map[string]string)

	return kv
}
```

### client.go

> 客户端可以将三种不同的 RPC 发送到键/值服务器： `Put(key, value)` 、 `Append(key, arg)` 和 `Get(key)` 。服务器维护键/值对的内存映射。键和值是字符串。 `Put(key, value)` 在映射中安装或替换特定键的值， `Append(key, arg)` 将 arg 追加到 key 的值并返回旧值，并 `Get(key)` 获取键的当前值。对于不存在的键，A `Get` 应返回一个空字符串。 `Append` 不存在的键应像现有值是零长度字符串一样。每个客户端都通过 `Clerk` Put/Append/Get 方法与服务器通信。A `Clerk` 管理 RPC 与服务器的交互。

```go
func (ck *Clerk) Get(key string) string {

	args := &GetArgs{
		Key: key,
	}
	reply := &GetReply{}
    
    // 循环直至请求成功
	for !ck.server.Call("KVServer.Get", args, reply) {
	} 
	return reply.Value

}

// 随机任务ID
func nrand() int64 {
	max := big.NewInt(int64(1) << 62)
	bigx, _ := rand.Int(rand.Reader, max)
	x := bigx.Int64()
	return x
}

func (ck *Clerk) PutAppend(key string, value string, op string) string {
	// 设置请求参数
	MessageID := nrand()
	arg := &PutAppendArgs{
		Key:         key,
		Value:       value,
		MessageID:   MessageID,
		MessageType: Modify,
	}
	reply := &PutAppendReply{}
    
    // 循环直至请求成功
	for !ck.server.Call("KVServer."+op, arg, reply) {
	}
    
    // ACK机制，确认到请求成功，发送请求删除server端的请求记录
	arg = &PutAppendArgs{
		MessageType: Report,
		MessageID:   MessageID,
	}
    
    // 循环直至请求成功
	for !ck.server.Call("KVServer."+op, arg, reply) {
	}
	return reply.Value
}

// put和append
func (ck *Clerk) Put(key string, value string) {
	ck.PutAppend(key, value, "Put")
}

func (ck *Clerk) Append(key string, value string) string {
	return ck.PutAppend(key, value, "Append")
}
```

# Grove-Primary Backup Replication

> [paper链接](https://pdos.csail.mit.edu/6.824/papers/grove.pdf)

## 简介

[参考文章链接](https://zhuanlan.zhihu.com/p/546498612)

# Raft

> [paper链接](https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf)

## 简介

- Raft 是一种用于管理复制日志的共识算法
- 保持复制日志的一致性是共识算法的工作，服务器上的共识模块接收来自客户端的命令，并将其添加到其日志中。它与其他服务器上的共识模块进行通信，以确保每个日志最终以相同的顺序包含相同的请求，即使某些服务器出现故障也是如此。
- Raft 通过首先选举一位杰出的领导者，然后让领导者完全负责管理复制的日志来实现共识。领导者接受来自客户端的日志条目，将它们复制到其他服务器上，并告诉服务器何时可以安全地将日志条目应用于其状态机。拥有领导者可以简化复制日志的管理。例如，领导者可以决定在日志中放置新条目的位置，而无需咨询其他服务器，并且数据以简单的方式从领导者流向其他服务器。领导者可能会失败或与其他服务器断开连接，在这种情况下，将选出新的领导者。

## 选举主节点

> [视频链接](https://www.bilibili.com/video/BV1so4y1r7eM/?spm_id_from=333.337.search-card.all.click)

- 对于在进行vote时，candidate向其他节点申请选票，其他节点进行判断，该candidate的term是否大于自身的tern值，candidate的提交日志的index是否大于自身的index值
- 当请求日志被过半的节点接受到后，leader就提交该日志

> 在Raft共识算法中，候选者（Candidate）向其他节点发起投票请求时，其他节点（Follower）判断是否向该候选者投票的流程如下：

1. **接收请求**：Follower接收到候选者发来的请求投票（RequestVote）RPC。

2. **比较任期**：

   - **请求者的任期较小**：如果候选者的任期（`args.Term`）小于Follower的当前任期（`currentTerm`），Follower会拒绝投票，并返回当前任期。
   - **请求者的任期较大**：如果候选者的任期大于Follower的当前任期，Follower会更新自己的任期，并将自己的状态重置为Follower，然后继续进行以下检查。

3. **检查投票权**：

   - 如果Follower已经在当前任期内投过票（`votedFor != -1`）且不是投给该候选者，Follower会拒绝投票。
   - 如果Follower没有在当前任期内投过票，或者之前投的票是给当前请求的候选者，则继续进行以下检查。

4. **检查日志的最新情况**（Raft论文图2中的日志匹配条件）：

   - 候选者的日志是否至少和自己一样新

     ：比较候选者日志的最后一条记录的任期（

     ```
     args.LastLogTerm
     ```

     ）和日志的长度（

     ```
     args.LastLogIndex
     ```

     ）。

     ![image-20240809104317907](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240809104317907.png)
     
     虽然日志最长，但是日志对应的任期小，其他节点都投反对票
     
     - 如果候选者的日志更长，或者候选者的日志长度相同但最后一条记录的任期更大，则Follower会投票给候选者。
     - 如果候选者的日志不如Follower的新，则Follower会拒绝投票。

5. **投票决定**：

   - 如果通过了上述所有检查，Follower会记录自己的投票情况（`votedFor = args.CandidateId`），并向候选者返回投票成功的响应。
   - 如果有任何检查不通过，Follower会拒绝投票。

## 日志压缩

![image-20240718090849021](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240718090849021.png)

- 将5之前的的数据进行快照覆盖，只保留数据的插入操作
- 后面的一点指令保存
- 就和redis的AOF和快照方式结合（也不对，就单纯AOF的压缩方式）一样的，就是AOF存储指令过多，统计后只保留最后每个数据的插入操作
- 在进行快照复制的时候，使用的是COW，写时复制

**COW**

- 在复制的时候，所对应的页帧设为只读，供给复制进程读取数据，如果这时有一个写的进程，则会将该页帧的数据读入内存，然后再进行修改，最后更新到新的位置上去，原来页帧的数据不会被更改，然后本来复制进程的指针还是指向原来页帧的地址，并不会读取到新数据，确保了复制进程的正确性

## Lab3

> 代码
>
> 参考文章链接 [知乎的](https://zhuanlan.zhihu.com/p/681385987)

### Part A

最基本的Leader选举程序

#### util.go

> 日志打印工具

```go
package raft

import (
	"fmt"
	"log"
	"os"
	"strconv"
	"time"
)

// 所要打印的日志类型
type logTopic string

const (
	DError logTopic = "ERRO" // level = 3  错误
	DWarn  logTopic = "WARN" // level = 2  警告
	DInfo  logTopic = "INFO" // level = 1  信息
	DDebug logTopic = "DBUG" // level = 0  DBUG

	// level = 1
	DClient  logTopic = "CLNT" // 客户端
	DCommit  logTopic = "CMIT" // 日志提交
	DDrop    logTopic = "DROP" // 丢弃日志
	DLeader  logTopic = "LEAD" // 领头人
	DLog     logTopic = "LOG1" // 发送 log
	DLog2    logTopic = "LOG2" // 接收 log
	DPersist logTopic = "PERS" // 持久化
	DSnap    logTopic = "SNAP" // 快照
	DTerm    logTopic = "TERM" // 任期
	DTest    logTopic = "TEST" // 测试
	DTimer   logTopic = "TIMR" // 时间
	DTrace   logTopic = "TRCE" // 路径
	DVote    logTopic = "VOTE" // 投票
	DApply   logTopic = "APLY" // 申请
)

// Debugging
const Debug = false

// 自带的数据打印
func DPrintf(format string, a ...interface{}) {
	if Debug {
		log.Printf(format, a...)
	}
}

// 数据打印等级
func getTopicLevel(topic logTopic) int {
	switch topic {
	case DError:
		return 3
	case DWarn:
		return 2
	case DInfo:
		return 1
	case DDebug:
		return 0
	default:
		return 1
	}
}

// 从运行环境中获得打印日志的级别
func getEnvLevel() int {
	v := os.Getenv("VERBOSE")
	level := getTopicLevel(DError) + 1
	if v != "" {
		var err error
		level, err = strconv.Atoi(v)
		if err != nil {
			log.Fatalf("Invalid verbosity %v", v)
		}
	}
	return level
}

// log开始时间和log级别
var logStart time.Time
var logLevel int

// 初始化
func init() {
    // 设置数据
	logLevel = getEnvLevel()
	logStart = time.Now()

	// do not print verbose date
	log.SetFlags(log.Flags() &^ (log.Ldate | log.Ltime))
}

// 打印日志
func LOG(peerId int, term int, topic logTopic, format string, a ...interface{}) {
	topicLevel := getTopicLevel(topic)
	if logLevel <= topicLevel {
		time := time.Since(logStart).Microseconds()
		time /= 100
        // 时间戳，任期，日志类别，节点ID
		prefix := fmt.Sprintf("%06d T%04d %v S%d ", time, term, string(topic), peerId)
		format = prefix + format
		log.Printf(format, a...)
	}
}
```

#### raft.go

> 大部分代码都在这
>
> **选举超时**：如果节点在选举超时后仍未收到心跳或附加日志条目的请求，则会发起选举，变为候选人，增加自己的任期并向其他节点请求投票。
>
> **请求投票**：节点可以通过`RequestVote`方法向其他节点请求投票，其他节点根据当前的任期和状态决定是否投票。
>
> **成为领导者**：如果候选人获得了多数节点的投票支持，就会成为领导者，并开始发送心跳信号或附加日志条目的请求。
>
> **日志复制**：领导者通过`AppendEntries`方法向其他节点复制日志，以确保所有节点的日志保持一致。

- raft的三种角色身份

  ```go
  type Role string
  
  const (
  	Follower  Role = "Follower"
  	Candidate Role = "Candidate"
  	Leader    Role = "Leader"
  )
  ```

- raft节点结构体

  ```go
  type Raft struct {
  	mu        sync.Mutex          // 锁
  	peers     []*labrpc.ClientEnd // 所有RPC节点的地址
  	persister *Persister          // 持久化存储
  	me        int                 // 当前节点的编号
  	dead      int32               // 杀死标志
  
  	role        Role // 当前节点的角色
  	currentTerm int  // 当前任期
  	votedFor    int  // 为哪个节点投票
  
  	electionStart   time.Time     // 选举开始时间
  	electionTimeout time.Duration // 选举超时时间
  
  }
  ```

- 变为候选者

  ```go
  func (rf *Raft) becomeCandidateLocked() {
  	if rf.role == Leader {
  		LOG(rf.me, rf.currentTerm, DVote, "Leadeer can't become Candidate")
  		return
  	}
  
  	LOG(rf.me, rf.currentTerm, DVote, "%s->Candidate, For T%d", rf.role, rf.currentTerm+1)
      
      // 变为候选者： 任期增加，身份改变，为自己投票
  	rf.currentTerm++
  	rf.role = Candidate
  	rf.votedFor = rf.me
  }
  ```

- 变为追随者

  ```go
  // 重置选举时间 -> 重置投票 -> 更新任期 -> 更新角色
  func (rf *Raft) becomeFollowerLocked(term int) {
      
      // 再次确定
  	if term < rf.currentTerm {
  		LOG(rf.me, rf.currentTerm, DError, "Can't become Follower, lower term: T%d", term)
  		return
  	}
  	LOG(rf.me, rf.currentTerm, DLog, "%s->Follower, For T%v->T%v", rf.role, rf.currentTerm, term)
  	rf.role = Follower
  	if term > rf.currentTerm {
          // 把之前投票记录删了
  		rf.votedFor = -1
  	}
  	rf.currentTerm = term
  }
  ```

- 变为领导者

  ```go
  // 成为领导者
  func (rf *Raft) becomeLeaderLocked() {
  	if rf.role != Candidate {
  		LOG(rf.me, rf.currentTerm, DError, "Only Candidate can become Leader")
  		return
  	}
  	LOG(rf.me, rf.currentTerm, DLeader, "%s->Leader, For T%d", rf.role, rf.currentTerm)
  	rf.role = Leader
  }
  ```

  

- 获取raft节点状态的函数

  ```go
  func (rf *Raft) GetState() (int, bool) {
  
  	var term int
  	var isleader bool
  
  	// 再上个锁
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  	return term, isleader
  }
  ```

- kill节点和查看是否dead，设置超时间，选举时间是否超时，

  ```go
  func (rf *Raft) Kill() {
  	atomic.StoreInt32(&rf.dead, 1)
  }
  
  func (rf *Raft) killed() bool {
  	z := atomic.LoadInt32(&rf.dead)
  	return z == 1
  }
  
  // 随机超时时间参数设置
  const (
  	electionTimeoutMin time.Duration = 250 * time.Millisecond
  	electionTimeoutMax time.Duration = 400 * time.Millisecond
  	replicateInterval  time.Duration = 250 * time.Millisecond
  )
  
  func (rf *Raft) resetElectionTimerLocked() {
  	rf.electionStart = time.Now()
      // 随机超时时间
  	randRange := int64(electionTimeoutMax - electionTimeoutMin)
  	rf.electionTimeout = electionTimeoutMin + time.Duration(rand.Int63()%randRange)
  }
  
  func (rf *Raft) isElectionTimeoutLocked() bool {
  	return time.Since(rf.electionStart) > rf.electionTimeout
  }
  ```

- 请求投票RPC的参数和回复数据结构

  ```go
  type RequestVoteArgs struct {
  	Term        int
  	CandidateId int
  }
  
  
  type RequestVoteReply struct {
  	Term        int
  	VoteGranted bool // true表示同意
  }
  	
  ```

- 处理请求投票的RPC逻辑，要是根据传入的参数决定是否给请求者投票

  ```go
  func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) {
  
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  
  	// 设置回复的任期
  	reply.Term = rf.currentTerm
  
      // 判断发送投票请求的任期是否比本身的任期旧
  	if args.Term < rf.currentTerm {
  		LOG(rf.me, rf.currentTerm, DVote, "-> S%d, Reject voted, Higher term, T%d>T%d", args, Candidate, rf.currentTerm, args.Term)
  		reply.VoteGranted = false
  		return
  	}
  
  	// 检查候选者的任期是否比自己的任期更新
  	if args.Term > rf.currentTerm {
  		rf.becomeFollowerLocked(args.Term)
  	}
  
  	// 检查是否已经为其他候选者投过票
      // 不等与-1的原因有：在变更为追随者的时候，任期变更，导致无法继续投票
  	if rf.votedFor != -1 {
  		LOG(rf.me, rf.currentTerm, DVote, "-> S%d, Reject, Already voted to S%d", args.CandidateId, rf.votedFor)
  		reply.VoteGranted = false
  		return
  	}
      
      // 设置成功投票信息
  	reply.VoteGranted = true
  	rf.votedFor = args.CandidateId
      
      // 更新发起选举的超时时间
  	rf.resetElectionTimerLocked()
  	LOG(rf.me, rf.currentTerm, DVote, "-> S%d, vote granted", args.CandidateId)
  }
  ```

- 发送请求投票的RPC请求

  ```go
  func (rf *Raft) sendRequestVote(server int, args *RequestVoteArgs, reply *RequestVoteReply) bool {
  	ok := rf.peers[server].Call("Raft.RequestVote", args, reply)
  	return ok
  }
  ```

- 定义了附加日志条目的RPC参数和回复结构

  ```go
  type AppendEntriesArgs struct {
  	Term     int
  	LeaderId int
  }
  type AppendEntriesReply struct {
  	Term    int
  	Success bool
  }
  ```

- 处理附加日志条目的RPC请求

  ```go
  func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  
  	// 判断发起日志请求的任期是否符合要求
  	if args.Term < rf.currentTerm {
  		LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log, Higher term, T%d<T%d", args.LeaderId, args.Term, rf.currentTerm)
  		return
  	}
  
      // 变为追随者
  	if args.Term >= rf.currentTerm {
  		rf.becomeFollowerLocked(args.Term)
  	}
  
      // 成功的话也算是日志心跳
  	rf.resetElectionTimerLocked()
  }
  ```

- 发送附加日志条目的RPC请求

  ```go
  func (rf *Raft) sendAppendEntries(server int, args *AppendEntriesArgs, reply *AppendEntriesReply) bool {
  	ok := rf.peers[server].Call("Raft.AppendEntries", args, reply)
  	return ok
  }
  ```

  

- 定期检查是否需要发起选举

  ```go
  func (rf *Raft) ticker() {
      // 当节点还存活的时候
  	for rf.killed() == false {
  
  		rf.mu.Lock()
  		defer rf.mu.Unlock()
  		// 为了线程安全 -> lock
  		if rf.role != Leader && rf.isElectionTimeoutLocked() {
              // 如果超时且不为Leader，则变为候选者并且发起选举
  			rf.becomeCandidateLocked()
  			go rf.startElection(rf.currentTerm)
  		}
  
  		// 随机等待时间
  		ms := 50 + (rand.Int63() % 300)
  		time.Sleep(time.Duration(ms) * time.Millisecond)
  	}
  }
  ```

- 创建一个新的Raft节点，并初始化其状态

  ```go
  // 结点状态
  func (rf *Raft) GetState() (int, bool) {
  	// 上个锁
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  	return rf.currentTerm, rf.role == Leader
  }
  func Make(peers []*labrpc.ClientEnd, me int,
  	persister *Persister, applyCh chan ApplyMsg) *Raft {
  	rf := &Raft{}
  	rf.peers = peers
  	rf.persister = persister
  	rf.me = me
  
  	// 初始化状态
  	rf.role = Follower
  	rf.currentTerm = 0
  	rf.votedFor = -1
  
  	// 恢复持久化的信息  后面的Part更详细
  	rf.readPersist(persister.ReadRaftState())
  
  	// 启动检测是否需要发起选举的线程
  	go rf.ticker()
  
  	return rf
  }
  ```

- 检测当前节点是否还处于选举的任期中

  ```go
  func (rf *Raft) contextLostLocked(role Role, term int) bool {
  	return !(rf.currentTerm == term && rf.role == role)
  }
  ```

- 定期发送日志复制请求

  ```go
  func (rf *Raft) replicationTicker(term int) {
      // 如果当前节点没被杀死
  	for rf.killed() == false {
  		ok := rf.startReplication(term)
          
          // 如果正常发送日志复制请求
  		if !ok {
  			break
  		}
  
  		rf.mu.Lock()
  
  		rf.mu.Unlock()
  
  		time.Sleep(replicateInterval)
  	}
  }
  ```

- 启动日志复制

  ```go
  func (rf *Raft) startReplication(term int) bool {
      
      // 构建日志复制节点函数
  	replicateToPeer := func(peer int, args *AppendEntriesArgs) {
  		reply := &AppendEntriesReply{}
  		ok := rf.sendAppendEntries(peer, args, reply)
  
  		rf.mu.Lock()
  		defer rf.mu.Unlock()
  
          // 网络冲突
  		if !ok {
  			LOG(rf.me, rf.currentTerm, DLog, "-> S%d, Lost or crashed", peer)
  			return
  		}
  
  		// 任期过旧，转为追随者
  		if reply.Term > rf.currentTerm {
  			rf.becomeFollowerLocked(reply.Term)
  			return
  		}
  	}
  
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  
      // 检测是否还在任期内
  	if rf.contextLostLocked(Leader, term) {
  		LOG(rf.me, rf.currentTerm, DLog, "Lost leader[%d] to %s[T%d]", rf.role, rf.currentTerm)
  		return false
  	}
  
      // 遍历所有节点，发送日志
  	for peer := 0; peer < len(rf.peers); peer++ {
  		if peer == rf.me {
  			continue
  		}
  
  		args := &AppendEntriesArgs{
  			Term:     rf.currentTerm,
  			LeaderId: rf.me,
  		}
  
  		go replicateToPeer(peer, args)
  
  	}
  
  	return true
  }
  ```

  

- 发起选举，并向其他节点发送请求投票的RPC

  ```go
  func (rf *Raft) startElection(term int) bool {
      // 记录获选票数
  	votes := 0
      
      // 向其他节点发送投票请求的函数，供给后面线程创建使用
  	askVoteFromPeer := func(peer int, args *RequestVoteArgs) {
  		reply := &RequestVoteReply{}
  		ok := rf.sendRequestVote(peer, args, reply)
  
  		// 处理响应
  		rf.mu.Lock()
  		defer rf.mu.Unlock()
          
          // 不同意该节点的选举
  		if !ok {
  			LOG(rf.me, rf.currentTerm, DDebug, "Ask vote from S%d, Lost or error", peer)
  			return
  		}
  
  		// 如果任期已经小于向申请投票节点的任期，则转变为追随者
  		if reply.Term > rf.currentTerm {
  			rf.becomeFollowerLocked(reply.Term)
  			return
  		}
  
  		// 检测是否还处于选举期间
  		if rf.contextLostLocked(Candidate, term) {
  			LOG(rf.me, rf.currentTerm, DVote, "Lost context, abort RequestVoteReply for S%d", peer)
  			return
  		}
  
  		// 其余情况则是同意选举，增加票数
  		if reply.VoteGranted {
  			votes++
  		}
  		// vote 数量大于一半
  		if votes > len(rf.peers)/2 {
  			rf.becomeLeaderLocked()
  			// 开启日志，向追随者同步日志
  			go rf.replicationTicker(term)
  		}
  	}
  
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  
  	// 检测是否还处于选举期间
  	if rf.contextLostLocked(Candidate, term) {
  		LOG(rf.me, rf.currentTerm, DVote, "Lost Candidate to %s, abort RequestVote", rf.role)
  		return false
  	}
  
      // 遍历所有节点，创建请求投票的线程
  	for peer := 0; peer < len(rf.peers); peer++ {
  		if peer == rf.me {
  			votes++ // 投票给自己
  			continue
  		}
  
  		args := &RequestVoteArgs{
  			Term:        rf.currentTerm,
  			CandidateId: rf.me,
  		}
  
  		go askVoteFromPeer(peer, args)
  	}
  	return true
  }
  ```

  

### Part B

日志复制过程

#### 添加类的属性

- 新增类 `LogEntry`

  ```go
  // interface{} 表示的是任意类型的数据，相当于Java的Object
  type LogEntry struct {
  	Term         int         // 用于区分不同的Leader任期
  	CommandValid bool        // 当前指令是否有效。如果无效，follower 可以拒绝复制
  	Command      interface{} // 表示可以存储任意类型
  }
  ```

- `ApplyMsg`  (也不算新增吧)

  ```go
  type ApplyMsg struct {
      // 该指令是否可用
  	CommandValid bool
      
      // 指令内容  函数的形式
  	Command      interface{}
      
      // 指令索引
  	CommandIndex int
  
  	// For 3D:
  	SnapshotValid bool
  	Snapshot      []byte
  	SnapshotTerm  int
  	SnapshotIndex int
  }
  ```

  

- `Raft`结构体中增加属性

  ```go
  // 存储日志
  log []LogEntry
  
  // 应用于Leader期间
  // 每个节点的日志位置信息
  nextIndex  []int
  matchIndex []int
  
  // 与状态机的交互，最大提交的日志索引 和 已经应用的日志索引
  commitIndex int
  lastApplied int
  
  // 应用交互通道
  applyCond   *sync.Cond
  applyCh     chan ApplyMsg
  ```

- `RequestVoteArgs`增加属性

  ```go
  // 候选者最新日志的索引和任期       用于判断是否可以向该候选者投票
  LastLogIndex int
  LastLogTerm  int
  ```

- `AppendEntriesArgs`日志复制请求参数增加

  ```go
  PrevLogIndex int        // 上一个日志的index
  PrevLogTerm  int        // 上一个日志的Term
  Entries      []LogEntry // 要追加的日志
  
  LeaderCommit int // Leader已经提交的日志索引
  ```

#### 函数增加和修改

- `Raft`属性增加了，那对应的`make`函数也要修改

  ```go
  // 对新属性的初始化
  rf.log = append(rf.log, LogEntry{})
  
  rf.matchIndex = make([]int, len(rf.peers))
  rf.nextIndex = make([]int, len(rf.peers))
  
  rf.applyCh = applyCh
  rf.commitIndex = 0
  rf.lastApplied = 0
  rf.applyCond = sync.NewCond(&rf.mu)
  
  // 启动循环检测日志提交的线程   这个函数在后面增加的
  go rf.applyTicker()
  ```

- `RequestVoteArgs`属性增加了，那对应发送请求的相关函数和处理请求的函数需要修改

  - `startElection`

    ```go
    func (rf *Raft) startElection(term int) bool {
        // ------------------以上忽略------------------- //
        
        // 统计获得的票数
        votes := 0
        
        askVoteFromPeer := func(peer int, args *RequestVoteArgs) {
            // ---------------------------------------//
            
            // 如果获得同意，增加票数
    		if reply.VoteGranted {
    			votes++
    		}
    		// vote 数量大于一半
    		if votes > len(rf.peers)/2 {
    			rf.becomeLeaderLocked()
    			// 开启日志追加线程 心跳逻辑
    			go rf.replicationTicker(term)
    		}
        }
        
        // ------------------------------------------ //
        // 当前日志 长度-索引
        l := len(rf.log)
        for peer := 0; peer < len(rf.peers); peer++ {
    		if peer == rf.me {
    			votes++ // 投票给自己
    			continue
    		}
    
    		args := &RequestVoteArgs{
    			Term:         rf.currentTerm,
    			CandidateId:  rf.me,
                // 携带日志相关信息
    			LastLogIndex: l - 1,
    			LastLogTerm:  rf.log[l-1].Term,
    		}
    
    		go askVoteFromPeer(peer, args)
    	}
        // ---------------------------------------- //
    }
    ```

  - `RequestVote` 增加对候选者的日志信息判断

    ```go
    // 新增函数  判断候选者的日志是否新于自身日志
    func (rf *Raft) isMoreUpToDateLocked(candidateIndex, candidateTerm int) bool {
    	l := len(rf.log)
    	lastTerm, lastIndex := rf.log[l-1].Term, l-1
    	LOG(rf.me, rf.currentTerm, DVote, "Compare last log, Me: [%d]T%d, Candidate: [%d]T%d", lastIndex, lastTerm, candidateIndex, candidateTerm)
    
    	if lastTerm != candidateTerm {
    		return lastTerm > candidateTerm
    	}
    	return lastIndex > candidateIndex
    }
    
    
    func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) {
    	// -----------------处理完任期和votedFor的判断-------------------- //
        
        // 判断日志新旧
        if rf.isMoreUpToDateLocked(args.LastLogIndex, args.LastLogTerm) {
    		LOG(rf.me, rf.currentTerm, DVote, "-> S%d, Reject Vote, S%d's log less up-to-date", args.CandidateId)
    		return
    	}
        
    }
    ```

  - `becomeLeaderLocked` 成为leader后更新一些日志信息

    ```go
    func (rf *Raft) becomeLeaderLocked() {
        // -------------- 身份转变为leader的相关信息处理 ---------------- //
        
    	// 成为leader后，需要以自己匹配的日志为基准，初始化nextIndex和matchIndex
    	for peer := 0; peer < len(rf.peers); peer++ {
    		rf.nextIndex[peer] = len(rf.log)
    		rf.matchIndex[peer] = 0
    	}
    }
    ```

- `AppendEntriesArgs` 更改后，对应的日志相关请求和函数也需要进行更改

  - `AppendEntries` 处理日志追加请求

    ```go
    func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
    	// ------------------ 判断完任期后 ------------------- //
        
        // 检验日志开始位置和任期是否匹配
    	if args.PrevLogIndex >= len(rf.log) {
    		LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log,  Follower log too short, Len:%d <= Prev:%d", args.LeaderId, len(rf.log), args.PrevLogIndex)
    		return
    	}
    
    	if rf.log[args.PrevLogIndex].Term != args.PrevLogTerm {
    		LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log, Prev log not match, [%d]: T%d != T%d", args.LeaderId, args.PrevLogIndex, rf.log[args.PrevLogIndex].Term, args.PrevLogTerm)
    		return
    	}
    
    	// 符合条件，追加日志
    	rf.log = rf.log[:args.PrevLogIndex+1]
    	rf.log = append(rf.log, args.Entries...)
    	LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Follower append logs: (%d, %d]", args.PrevLogIndex, args.PrevLogIndex+len(args.Entries))
    	reply.Success = true
    
        // 如果Leader的提交日志索引大于本身的索引  则唤醒提交线程向状态机进行提交
    	if args.LeaderCommit > rf.commitIndex {
    		LOG(rf.me, rf.currentTerm, DApply, "Follower update the commit index %d->%d", rf.commitIndex, args.LeaderCommit)
    
    		// 注意边界条件  更新索引
    		if rf.commitIndex >= len(rf.log) {
    			rf.commitIndex = len(rf.log) - 1
    		} else {
    			rf.commitIndex = args.LeaderCommit
    		}
            // 唤醒线程
    		rf.applyCond.Signal()
    	}
    
        // 重新设置选举超时时间  算是收到一次心跳->重新开始计时
    	rf.resetElectionTimerLocked()
    }
    ```

  - `startReplication` 发送日志追加请求的相关参数设置     处理响应后的结果

    ```go
    // 新增函数 获得大多数节点已复制到的日志索引
    func (rf *Raft) getMajorityIndexLocked() int {
    	tmpIndexes := make([]int, len(rf.matchIndex))
    	copy(tmpIndexes, rf.matchIndex)
        
        // 先排序
    	sort.Ints(sort.IntSlice(tmpIndexes))
        
        // 获得过半的数量
    	majorityIdx := (len(tmpIndexes) - 1) / 2
    	LOG(rf.me, rf.currentTerm, DDebug, "Match index after sort: %v, majority[%d]=%d", tmpIndexes, majorityIdx, tmpIndexes[majorityIdx])
    	return tmpIndexes[majorityIdx] // min -> max
    }
    
    func (rf *Raft) startReplication(term int) bool {
        replicateToPeer := func(peer int, args *AppendEntriesArgs) {
            // -------------- 发送完请求后，并保持着Leader身份 --------------- //
            
            // 如果日志追加失败，往前回退
            // Leader的日志过于超前Follow节点的日志
    		if !reply.Success {
    			idx := rf.nextIndex[peer] - 1
    			term := rf.log[idx].Term
    			for idx > 0 && rf.log[idx].Term == term {
    				idx--
    			}
    			rf.nextIndex[peer] = idx + 1
    		} else {
                
    			// 成功，更新nextIndex和matchIndex
    			rf.matchIndex[peer] = args.PrevLogIndex + len(args.Entries)
    			rf.nextIndex[peer] = rf.matchIndex[peer] + 1 // 必须更新
                
                // 获得当前大多数的日志复制索引
    			majorityMatched := rf.getMajorityIndexLocked()
    
                // 大于当前提交的索引 则唤醒线程更新提交
    			if majorityMatched > rf.commitIndex {
    				LOG(rf.me, rf.currentTerm, DApply, "Leader update the commit index %d->%d", rf.commitIndex, majorityMatched)
    				rf.commitIndex = majorityMatched
    				rf.applyCond.Signal()
    			}
    		}
        }
        
        // ---------------------------------------------------- //
        for peer := 0; peer < len(rf.peers); peer++ {
    		if peer == rf.me {
                // 更新自身的日志索引参数
    			rf.matchIndex[peer] = len(rf.log) - 1
    			rf.nextIndex[peer] = len(rf.log)
    			continue
    		}
    		prevIdx := rf.nextIndex[peer] - 1
    
    		args := &AppendEntriesArgs{
    			Term:         rf.currentTerm,
    			LeaderId:     rf.me,
                
                // 日志追加请求参数设置
    			PrevLogIndex: prevIdx,
    			PrevLogTerm:  rf.log[prevIdx].Term,
    			Entries:      rf.log[prevIdx+1:],
    		}
    
    		go replicateToPeer(peer, args)
    
    	}
    }
    ```

  - `applyTicker` 监听向状态机提交日志的线程函数

    ```go
    func (rf *Raft) applyTicker() {
        
        // 当前节点未被杀死
    	for !rf.killed() {
    		rf.mu.Lock()
            
            // 等待唤醒  -> 再去提交新日志
    		rf.applyCond.Wait() // 阻塞 go routine 执行
    		entries := make([]LogEntry, 0)
            
    		// 从上一个提交的位置+1开始
    		for i := rf.lastApplied + 1; i <= rf.commitIndex; i++ {
    			entries = append(entries, rf.log[i])
    		}
    		rf.mu.Unlock()
    		// 将一个 log 发送到 rf.applyCh 中
    		for i, entry := range entries {
                // 向提交通道提交指令
    			rf.applyCh <- ApplyMsg{
    				CommandValid: entry.CommandValid,
    				Command:      entry.Command,
    				CommandIndex: rf.lastApplied + 1 + i,
    			}
    		}
    
    		rf.mu.Lock()
    		LOG(rf.me, rf.currentTerm, DApply, "Apply log for [%d, %d]", rf.lastApplied+1, rf.lastApplied+len(entries))
            
            // 更新lastApplied
    		rf.lastApplied += len(entries)
    		rf.mu.Unlock()
    	}
    }
    ```

### Part C

> 持久化(开个头)，优化日志追加逻辑

#### persister.go

- `persistLocked` 持久化节点的相关信息

  ```go
  // 持久化  currentTerm，votedFor，log
  func (rf *Raft) persistLocked() {
      
      // 我的理解就是 
      // 创建一个writer 然后以这个writer为基础去构造编码器，将所需要编写的内容都传进去编码
  	w := new(bytes.Buffer)
  	e := labgob.NewEncoder(w)
  	e.Encode(rf.currentTerm)
  	e.Encode(rf.votedFor)
  	e.Encode(rf.log)
  	raftstate := w.Bytes()
  	// 第二个nil留给 PartD
  	rf.persister.Save(raftstate, nil)
  }
  ```

#### raft.go

- `readPersist`  读取持久化的内容    源代码有给模板，参考实现即可

  ```go
  // 获得这个节点从持久化那边读取到的信息
  func (rf *Raft) persistString() string {
  	return fmt.Sprintf("T%d, VotedFor: %d, Log: [0: %d)", rf.currentTerm, rf.votedFor, len(rf.log))
  }
  
  func (rf *Raft) readPersist(data []byte) {
  	if data == nil || len(data) < 1 { // bootstrap without any state?
  		return
  	}
  	
      // 读取对应的信息
  	var currentTerm int
  	var votedFor int
  	var log []LogEntry
  
      // reader
  	r := bytes.NewBuffer(data)
      
      // 解码器
  	d := labgob.NewDecoder(r)
      
      // 获取信息
  	if err := d.Decode(&currentTerm); err != nil {
  		LOG(rf.me, rf.currentTerm, DPersist, "Read currentTerm error: %v", err)
  		return
  	}
  	rf.currentTerm = currentTerm
  
  	if err := d.Decode(&votedFor); err != nil {
  		LOG(rf.me, rf.currentTerm, DPersist, "Read votedFor error: %v", err)
  		return
  	}
  	rf.votedFor = votedFor
  
  	if err := d.Decode(&log); err != nil {
  		LOG(rf.me, rf.currentTerm, DPersist, "Read log error: %v", err)
  		return
  	}
  	rf.log = log
  	LOG(rf.me, rf.currentTerm, DPersist, "Read Persist %v", rf.persistString())
  }
  ```

- `AppendEntriesReply` 增加以下属性

  ```go
  // 冲突日志位置和任期信息
  ConflictIndex int
  ConflictTerm int
  ```

- `AppendEntries`  在对PrevLogIndex的处理进行优化

  ```go
  // 增加常量 
  const (
          InvalidIndex int = 0
          InvalidTerm  int = 0
  )
  
  // 增加函数 找到第一个term的日志
  func (rf *Raft) firstLogFor(term int) int {
          for i, entry := range rf.log {
                  if entry.Term == term {
                          return i
                  } else if entry.Term > term {
                          break
                  }
          }
          return InvalidIndex
  }
  func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
  	// ----------------------------------------------------- //
      
      // 检验日志开始位置和任期是否匹配
      if args.PrevLogIndex >= len(rf.log) {
          // follow的log太短
          LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log,  Follower log too short, Len:%d <= Prev:%d", args.LeaderId, len(rf.log), args.PrevLogIndex)
          reply.ConflictIndex = len (rf.log)
          reply.ConflictTerm = InvalidTerm
          return
      }
  
      if rf.log[args.PrevLogIndex].Term != args.PrevLogTerm {
          // log的任期不匹配
          LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log, Prev log not match, [%d]: T%d != T%d", args.LeaderId, args.PrevLogIndex, rf.log[args.PrevLogIndex].Term, args.PrevLogTerm)
  
          // 返回该冲突任期的第一个日志的Index，作为下次的NextIndex
          reply.ConflictTerm = rf.log[args.PrevLogIndex].Term
          reply.ConflictIndex = rf. firstLogFor (reply.ConflictTerm)
          return
      }
      
      // ---------------------------------------------------- //
  }
  ```

- `startReplication`对log的响应进行冲突处理

  ```go
  func (rf *Raft) startReplication(term int) bool {
  	// --------------------------------------- //
  	
  	if !reply.Success {
          prevNext := rf.nextIndex[peer]
          if reply.ConflictTerm == InvalidTerm {
              rf.nextIndex[peer] = reply.ConflictIndex // 如果没有，从这开始，以 Follower 为准
          } else {
              firstTermIndex := rf.firstLogFor (reply.ConflictTerm) //
              // 不存在
              if firstTermIndex == InvalidIndex {
                  rf.nextIndex[peer] = reply.ConflictIndex  // 如果没有，从这开始，以 Follower 为准
              } else {
                  rf.nextIndex[peer] = firstTermIndex + 1  // 以 Leader 为准，firstTermIndex + 1
              }
          }
          // avoid the late reply move the nextIndex forward again
          /* 当匹配探测期（AppendEntries RPC）的时间比较长的时候，
          会有多个探测的 RPC  在同一时刻发送给 Followers，
          如果 RPC 结果乱序回来，就会导致问题：
  
          一个先发出去的探测 RPC 后回来了，
          其中所携带的 ConflictTerm 和 ConflictIndex 就有可能造成 rf.next 的“反复横跳”。
  
          为了解决这个问题，我们可以强制要求 Leader 中的 nextIndex 必须单调递减，
          也就是说，每次调整 nextIndex 的时候，都要比之前更小，从而避免问题。
          */
          rf.nextIndex[peer] = min(prevNext, rf.nextIndex[peer])
          return
      }else {
          // 成功，更新nextIndex和matchIndex
  
          rf.matchIndex[peer] = args.PrevLogIndex + len(args.Entries)
          rf.nextIndex[peer] = rf.matchIndex[peer] + 1 // important: must update
          majorityMatched := rf.getMajorityIndexLocked()
          
          // 这边多加了一个判断  只提交当前任期的日志
          if majorityMatched > rf.commitIndex && rf.log[majorityMatched].Term == rf.currentTerm {
              LOG(rf.me, rf.currentTerm, DApply, "Leader update the commit index %d->%d", rf.commitIndex, majorityMatched)
              rf.commitIndex = majorityMatched
              rf.applyCond.Signal()
          }
      }
  	
  	// --------------------------------------- //
  }
  ```

  ![image-20240721161739628](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240721161739628.png)

​	**提前把不是自己任期的日志提交就会像d一样出现错误**

​	**只有当能提交自己任期的日志时，才会顺带将之前的日志进行提交**

### Part D

> 压缩日志和快照

#### RaftLog

> 前面存储log直接用数组
>
> 现在使用快照和数组结合

- `RaftLog` 结构体构造

  ```go
  type RaftLog struct {
  	// 快照中最后一个日志的索引和任期
  	snapLastIdx  int
  	snapLastTerm int
  	// contains index [1, snapLastIdx]
  	// 快照
  	snapshot []byte
  	// the first entry is `snapLastIdx`, but only contains the snapLastTerm
  	// the entries between (snapLastIdx, snapLastIdx+len(tailLog)-1] have real data
  	tailLog []LogEntry
  }
  
  // 日志大小  长度  替代之前的 len(rf.log)
  func (rl *RaftLog) size() int {
  	return rl.snapLastIdx + len(rl.tailLog)
  }
  
  // 获取日志的实际索引 判断是否越界
  func (rl *RaftLog) idx(logicIdx int) int {
  	if logicIdx < rl.snapLastIdx || logicIdx >= rl.size() {
  		panic(fmt.Sprintf("%d is out of [%d, %d]", logicIdx, rl.snapLastIdx+1, rl.size()-1))
  	}
  	return logicIdx - rl.snapLastIdx
  }
  
  // 获取日志
  func (rl *RaftLog) at(logicIdx int) LogEntry {
  	return rl.tailLog[rl.idx(logicIdx)]
  }
  
  // 获取最后一个日志 索引 任期
  func (rl *RaftLog) last() (idx, term int) {
  	return rl.size() - 1, rl.tailLog[len(rl.tailLog)-1].Term
  }
  
  // 获得从指定索引开始的日志
  func (rl *RaftLog) tail(startIdx int) []LogEntry {
  	if startIdx >= rl.size() {
  		return nil
  	}
  	return rl.tailLog[rl.idx(startIdx):]
  }
  
  // 找到第一个term的日志
  func (rl *RaftLog) firstLogFor(term int) int {
  	for idx, entry := range rl.tailLog {
  		if entry.Term == term {
  			return idx
  		} else if entry.Term > term {
  			break
  		}
  	}
  	return InvalidIndex
  }
  
  // 追加日志  这个好像没啥用
  func (rl *RaftLog) append(e LogEntry) {
  	rl.tailLog = append(rl.tailLog, e)
  }
  
  // 追加日志数组
  func (rl *RaftLog) appendFrom(prevIdx int, entries []LogEntry) {
  	rl.tailLog = append(rl.tailLog[:rl.idx(prevIdx)+1], entries...)
  }
  
  // 持久化日志里的除了快照的数据
  func (rl *RaftLog) persist(e *labgob.LabEncoder) {
  	e.Encode(rl.snapLastIdx)
  	e.Encode(rl.snapLastTerm)
  	e.Encode(rl.tailLog)
  }
  
  // 从快照中读取数据
  func (rl *RaftLog) readPersist(d *labgob.LabDecoder) error {
  	var lastIdx int
  	if err := d.Decode(&lastIdx); err != nil {
  		return fmt.Errorf("decode last include index failed")
  	}
  	rl.snapLastIdx = lastIdx
  
  	var lastTerm int
  	if err := d.Decode(&lastTerm); err != nil {
  		return fmt.Errorf("decode last include term failed")
  	}
  	rl.snapLastTerm = lastTerm
  
  	var log []LogEntry
  	if err := d.Decode(&log); err != nil {
  		return fmt.Errorf("decode tail log failed")
  	}
  	rl.tailLog = log
  
  	return nil
  }
  
  // 初始化构造函数
  func NewLog(snapLastIdx, snapLastTerm int, snapshot []byte, entries []LogEntry) *RaftLog {
  	rl := &RaftLog{
  		snapLastIdx:  snapLastIdx,
  		snapLastTerm: snapLastTerm,
  		snapshot:     snapshot,
  	}
  
  	// 从0开始, 容量 cap = 1 + len(entries)
  	rl.tailLog = make([]LogEntry, 0, 1+len(entries))
      
      // 追加第一个log 
  	rl.tailLog = append(rl.tailLog, LogEntry{
  		Term: snapLastTerm,
  	})
  	rl.tailLog = append(rl.tailLog, entries...)
  
  	return rl
  }
  
  // 做快照
  func (rl *RaftLog) doSnapshot(index int, snapshot []byte) {
      
      // 避免重复快照
  	if index <= rl.snapLastIdx {
  		return
  	}
  	// 当前index在log数组中的实际位置
  	idx := rl.idx(index)
  
      // 更改之前存储的数据
  	rl.snapLastTerm = rl.tailLog[idx].Term
  	rl.snapLastIdx = index
  	rl.snapshot = snapshot
  
  	// 分配新log的空间
  	newLog := make([]LogEntry, 0, rl.size()-rl.snapLastIdx)
  	newLog = append(newLog, LogEntry{
  		Term: rl.snapLastTerm,
  	})
      
      // 将剩余的log复制到新log数组中
  	newLog = append(newLog, rl.tailLog[idx+1:]...)
  
      // 替换旧数组
  	rl.tailLog = newLog
  }
  
  // 接受Leader发来的快照，进行更新
  func (rl *RaftLog) installSnapshot(index, term int, snapshot []byte) {
  	rl.snapLastIdx = index
  	rl.snapLastTerm = term
  	rl.snapshot = snapshot
  
  	// 接受了新快照，说明之前存储的log数组没用了，就分配1个空间初始化即可
  	newLog := make([]LogEntry, 0, 1)
  	newLog = append(newLog, LogEntry{
  		Term: rl.snapLastTerm,
  	})
  	rl.tailLog = newLog
  }
  ```

- `RaftLog` 对应的初始化，影响等

  ```go
  // 在make函数中
  rf.log = NewLog(InvalidIndex, InvalidTerm, nil, nil)  //初始化
  
  // 获得指定位置的log
  rf.log.at(args.PrevLogIndex)
  ```

#### 修改部分持久化函数

- `readPersist`

  ```go
  func (rf *Raft) readPersist(data []byte) {
  	
  	// -------------到获得voteFor------------------  //
      
      // 本来是获得log数组，替换成如下
  	if err := rf.log.readPersist(d); err != nil {
  		LOG(rf.me, rf.currentTerm, DPersist, "Read log error: %v", err)
  		return
  	}
  
  	rf.log.snapshot = rf.persister.ReadSnapshot()
  
  	if rf.log.snapLastIdx > rf.commitIndex {
  		rf.commitIndex = rf.log.snapLastIdx
  		rf.lastApplied = rf.log.snapLastIdx
  	}
  	LOG(rf.me, rf.currentTerm, DPersist, "Read Persist %v", rf.persistString())
  }
  ```

- `persistLocked`

  ```go
  func (rf *Raft) persistLocked() {
  	// --------- 更改对log的编码 --------- //
  	rf.log.persist(e)
  	raftstate := w.Bytes()
  	// leave the second parameter nil, will use it in PartD
  	rf.persister.Save(raftstate, rf.log.snapshot)
  }
  ```

  

#### Snapshot 

> 快照

- RPC请求相关

  ```go
  // Raft追加属性
  // 判断当前 apply 的内容是 snapshot，还是普通的 log
  snapPending bool
  
  // 给Follow发送快照RPC的参数
  type InstallSnapshotArgs struct {
  	Term     int
  	LeaderId int
  
  	// 最后一个包含在快照中的日志条目的索引 和 任期
  	LastIncludedIndex int
  	LastIncludedTerm  int
  
  	Snapshot []byte
  }
  
  // 打印快照参数
  func (args *InstallSnapshotArgs) String() string {
  	return fmt.Sprintf("Leader-%d, T%d, Last: [%d]T%d", args.LeaderId, args.Term, args.LastIncludedIndex, args.LastIncludedTerm)
  }
  
  // Follower对快照RPC的回复
  type InstallSnapshotReply struct {
  	Term int
  }
  
  // 打印快照回复
  func (reply *InstallSnapshotReply) String() string {
  	return fmt.Sprintf("T%d", reply.Term)
  }
  
  // follower 处理复制快照RPC调用
  func (rf *Raft) InstallSnapshot(args *InstallSnapshotArgs, reply *InstallSnapshotReply) {
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  	LOG(rf.me, rf.currentTerm, DDebug, "<- S%d, RecvSnap, Args=%v", args.LeaderId, args.String())
  
      // 例行检查任期
  	reply.Term = rf.currentTerm
  
  	if args.Term < rf.currentTerm {
  		LOG(rf.me, rf.currentTerm, DSnap, "<- S%d, Reject Snap, Higher Term, T%d>T%d", args.LeaderId, rf.currentTerm, args.Term)
  		return
  	}
      // 转为follow节点
  	if args.Term >= rf.currentTerm {
  		rf.becomeFollowerLocked(args.Term)
  	}
  
  	// 要复制的快照最后的日志索引是否大于自身的快照索引
  	if rf.log.snapLastIdx >= args.LastIncludedIndex {
  		LOG(rf.me, rf.currentTerm, DSnap, "<- S%d, Reject Snap, Already installed, Last: %d>=%d", args.LeaderId, rf.log.snapLastIdx, args.LastIncludedIndex)
  		return
  	}
  	// 更新自身快照
  	rf.log.installSnapshot(args.LastIncludedIndex, args.LastIncludedTerm, args.Snapshot)
  	rf.persistLocked()
  	rf.snapPending = true
  	rf.applyCond.Signal()
  }
  
  // Leader 发送RPC请求  将快照传递给Follow节点
  func (rf *Raft) sendInstallSnapshot(server int, args *InstallSnapshotArgs, reply *InstallSnapshotReply) bool {
  	ok := rf.peers[server].Call("Raft.InstallSnapshot", args, reply)
  	return ok
  }
  ```

- 对`snapshot`的使用

  ```go
  // 在处理快照之前的一个判断
  func (rf *Raft) Snapshot(index int, snapshot []byte) {
  	// Your code here (3D).
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  	LOG(rf.me, rf.currentTerm, DSnap, "Snap on %d", index)
  
  	// 不接受还没有提交的快照
  	if index > rf.commitIndex {
  		LOG(rf.me, rf.currentTerm, DSnap, "Couldn't snapshot before CommitIdx: %d>%d", index, rf.commitIndex)
  		return
  	}
  
  	// 不接受已经有快照的日志
  	if index <= rf.log.snapLastIdx {
  		LOG(rf.me, rf.currentTerm, DSnap, "Already snapshot in %d<=%d", index, rf.log.snapLastIdx)
  		return
  	}
  
  	rf.log.doSnapshot(index, snapshot)
  	rf.persistLocked()
  }
  ```

- 在追加日志前的判断

  ```go
  func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
  	// ------------------------------------------------ //
  	
  	// 检测上一个日志的索引是否小于快照的最后一个索引
  	if args.PrevLogIndex < rf.log.snapLastIdx {
  		reply.ConflictTerm = rf.log.snapLastTerm
  		reply.ConflictIndex = rf.log.snapLastIdx
  		LOG(rf.me, rf.currentTerm, DLog2, "<- S%d, Reject log, Follower log truncated in %d", args.LeaderId, rf.log.snapLastIdx)
  		return
  	}
  	
  	// ------------------------------------------------ //
  }
  ```

- 在`startReplication` 中对快照的处理

  ```go
  func (rf *Raft) startReplication(term int) bool {
  	// ----------------- replicateToPeer ------------------ //
  	
      // 调用RPC 将快照复制到Follow节点上
  	installOnPeer := func(peer int, term int, args *InstallSnapshotArgs) {
  		reply := &InstallSnapshotReply{}
  		ok := rf.sendInstallSnapshot(peer, args, reply)
  
  		rf.mu.Lock()
  		defer rf.mu.Unlock()
  		if !ok {
  			LOG(rf.me, rf.currentTerm, DSnap, "-> S%d, Lost or crashed", peer)
  			return
  		}
  		LOG(rf.me, rf.currentTerm, DDebug, "-> S%d, Append, Reply=%v", peer, reply.String())
  
  		// 例行检查任期
  		if reply.Term > rf.currentTerm {
  			rf.becomeFollowerLocked(reply.Term)
  			return
  		}
  
  		if rf.contextLostLocked(Leader, term) {
  			LOG(rf.me, rf.currentTerm, DLog, "-> S%d, Context Lost, T%d:Leader->T%d:%s", peer, term, rf.currentTerm, rf.role)
  			return
  		}
  
  		// 确保要发送的快照大于匹配到的日志索引
  		if args.LastIncludedIndex > rf.matchIndex[peer] { // to avoid disorder reply
  			rf.matchIndex[peer] = args.LastIncludedIndex
  			rf.nextIndex[peer] = args.LastIncludedIndex + 1
  		}
  
  		// note: we need not try to update the commitIndex again,
  		// because the snapshot included indexes are all committed
  	}
      
      for peer := 0; peer < len(rf.peers); peer++ {
          // -------------------------------- //
          
          // 要发送的条目的上一个条目，探针
  		prevIdx := rf.nextIndex[peer] - 1
  
  		if prevIdx < rf.log.snapLastIdx {
  			args := &InstallSnapshotArgs{
  				Term:              rf.currentTerm,
  				LeaderId:          rf.me,
  				LastIncludedIndex: rf.log.snapLastIdx,
  				LastIncludedTerm:  rf.log.snapLastTerm,
  				Snapshot:          rf.log.snapshot,
  			}
  			LOG(rf.me, rf.currentTerm, DDebug, "-> S%d, SendSnap, Args=%v", peer, args.String())
              
              // 创建线程 发送RPC请求
  			go installOnPeer(peer, term, args)
  			continue
  		}
          
          // ----------------------------------- //
      }
  }
  ```

- `applyTricker` 中对快照的处理

  ```go
  func (rf *Raft) applyTicker() {
  	for !rf.killed() {
  		rf.mu.Lock()
  		rf.applyCond.Wait() // 阻塞 go routine 执行
  		entries := make([]LogEntry, 0)
  		// should start from rf.lastApplied+1 instead of rf.lastApplied
  		snapPendingApply := rf.snapPending
  
          // 如果不是含快照的提交 
  		if !snapPendingApply {
  			// 改造 log，找到 entries
  			if rf.lastApplied < rf.log.snapLastIdx {
  				rf.lastApplied = rf.log.snapLastIdx
  			}
  
  			start := rf.lastApplied + 1
  			end := rf.commitIndex
  			if end >= rf.log.size() {
  				end = rf.log.size() - 1
  			}
              // 从上次提交到现在的提交索引
  			for i := start; i <= end; i++ {
  				entries = append(entries, rf.log.at(i))
  			}
  		}
  		rf.mu.Unlock()
  
          // 如果不是含快照的提交 
  		if !snapPendingApply {
              // 同步状态机  发送命令
  			for i, entry := range entries {
  				rf.applyCh <- ApplyMsg{
  					CommandValid: entry.CommandValid,
  					Command:      entry.Command,
  					CommandIndex: rf.lastApplied + 1 + i, // must be cautious
  				}
  			}
  		} else {
              // 否则发送快照信息
  			rf.applyCh <- ApplyMsg{
  				SnapshotValid: true,
  				Snapshot:      rf.log.snapshot,
  				SnapshotIndex: rf.log.snapLastIdx,
  				SnapshotTerm:  rf.log.snapLastTerm,
  			}
  		}
  
  		rf.mu.Lock()
          
          // 如果不是含快照的提交 
  		if !snapPendingApply {
  			LOG(rf.me, rf.currentTerm, DApply, "Apply log for [%d, %d]", rf.lastApplied+1, rf.lastApplied+len(entries))
  			rf.lastApplied += len(entries)
  		} else {
  			LOG(rf.me, rf.currentTerm, DApply, "Install Snapshot for [0, %d]", rf.log.snapLastIdx)
  			// 更新 rf.lastApplied 和 rf.commitIndex
              // 在提交快照时，的范围可能超过已提交内容，因为本身可能远远落后于Leader节点
  			rf.lastApplied = rf.log.snapLastIdx
  			if rf.commitIndex < rf.lastApplied {
  				rf.commitIndex = rf.lastApplied
  			}
  			rf.snapPending = false
  		}
  
  		rf.mu.Unlock()
  	}
  }
  
  ```


# Zookeeper

> [论文链接地址](https://pdos.csail.mit.edu/6.824/papers/zookeeper.pdf)
>
> 像redis是KV存储系统，zookeeper更多是文件形式，他有个自己的命名方式，去构建对应的文件树，并且自身有一套更高级1协调原语，去保证程序的正确运行

## 一些概念吧

### 基础原语

- 配置管理
- **Rendezvous** （会合）
- 集群成员管理
- 简单的锁机制 （没有羊群效应）
  - 客户端申请锁的时候，会创建一个文件名称加编号
  - 并获取所有文件名称列表(ListFile)
  - 判断当前最小编号是否是自身，是则获得锁
  - 否则使用Exist去监听前一个文件
  - 锁的释放机制就是删除对应文件和编号，就会通知监听该文件的客户端，使其获得锁
- 读写锁
- 双屏障   （客户端对一个zNode进行注册）

## zookeeper的实现

- 对于请求，如果是需要更改数据的写请求，会进行原子广播，zab保证更改的顺序，对于这些操作也会保存在数据库(快照)中。
- 处理请求严格按照FIFO的原则
- 在选举主节点上，和raft有些相似之处

## 视频

![image-20240725131307901](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240725131307901-1721884388534-1.png)

**历史线性一致性**

- 这个是从客户端观测到的

**虽说Wx1的请求先到达，但是Wx2的操作先执行，肯能是收到cpu调度的影响或者是争夺锁的过程**

**zookeeper**

- 在处理写和读的请求上，写是保持线性一致性，确保用户的写请求线性执行
- 读的请求，连续发送几个读请求，第一次读请求或者写请求后，会获得Zindex，在发送下一个读请求时，服务端节点回去判断自身是否是新的或者更新的版本，如果不是则会等待Leader更新
- ![image-20240725164659798](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240725164659798.png)
- 在执行write之前，确保先将ready被删除这个事件通知给所有正在监听这个文件的节点

**ZNode**

- zookeeper里头创建了一个类文件系统（只是个命名系统），每个应用有自己的命名空间去区分开
- 开放一些类文件操作的API接口：Create(数据和节点类型)、Delete(版本号)、Exist(是否增加监视器Watch)、GetData(监视器选项)、SetData(数据和版本号)、ListFile

# DynamoDb

> [paper链接](https://pdos.csail.mit.edu/6.824/papers/atc22-dynamodb.pdf)
>
> 好像是很牛的nosql数据库

## 基础概念

好像和MongoDB有点像，都是以集合来管理数据，每个集合有一个主键，创建的时候配置的，也支持索引，ACID

统一由一个autoadmin 去管理集群，判断节点是否挂掉

将表数据分区存储是DynamoDb的核心，根据分区配置吞吐量，并限制客户端请求的吞吐量

 DynamoDB 实施了一个系统，可以根据吞吐量消耗和存储主动平衡跨存储节点分配的分区，以减轻紧密包装的副本造成的可用性风险。

在耐久性和正确性上，DynamoDb也有对应的备份策略，故障处理策略

为了实现高可用性，DynamoDB 表在一个区域中的多个可用区 (AZ) 之间分布和复制。 DynamoDB 定期测试对节点、机架和可用区故障的恢复能力

请求路由器需要的最重要的元数据之一是表的主键和存储节点之间的映射

**视频里的话，讲的更多是对于数据库的备份，由一个法定的数量**

![image-20240726162759318](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240726162759318.png)

**保证R+W=N+1，这样两者至少有一个重叠，写的时候只要有w个响应几个，读的时候读r个，并从中找到版本号最大的数据**

## Lab 4

> 基于Raft的KV存储服务
>
> 好像和这个数据库没啥关系哈哈

### 前期准备

- 首先嘛，要把前面的Lab 3 Raft做完，包括ABCD

- 把`Raft.go` 的`Start`函数完善

  该函数是`server`端接受请求时访问将指令传递给`raft`，如果是`Leader`则存储改指令，并由后面的replication线程去完成集群间的同步

  ```go
  func (rf *Raft) Start(command interface{}) (int, int, bool) {
  	// Your code here (3B).
  	rf.mu.Lock()
  	defer rf.mu.Unlock()
  	term := rf.currentTerm
  	isLeader := rf.role == Leader
  
  	if isLeader {
  		en := LogEntry{Term: term, CommandValid: true, Command: command}
  		rf.log.tailLog = append(rf.log.tailLog, en)
  		rf.nextIndex[rf.me] = rf.log.size() + 1
  		rf.persistLocked()
  		// 剩下就交给replicationTicker去处理  (将该日志复制)
  		DPrintf("[start]:me: %d,log:%v\n", rf.me, rf.log)
  	} else {
  		return -1, term, isLeader
  	}
  
  	return rf.log.size() + 1, term, isLeader
  }
  ```

### common.go

> 一些配置

- 常量定义

  ```go
  // raft集群返回的状态码
  const (
  	OK             = "OK"
  	ErrNoKey       = "ErrNoKey"
  	ErrWrongLeader = "ErrWrongLeader"
  	ErrTimeOut     = "ErrTimeOut"
  )
  
  // 错误
  type Err string
  ```

- 请求和返回参数设定

  ```go
  // Put 或者 Append
  type PutAppendArgs struct {
  	Key   string
  	Value string
  
  	Op       string // "Put" 或者 "Append"
  	ClientId int64  // 客户端Id
  	OptionId int    // 当前客户端的第几条命令
  }
  
  type PutAppendReply struct {
  	Err Err
  }
  
  type GetArgs struct {
  	Key string
  
  	ClientId int64 // 客户端Id
  	OptionId int   // 当前客户端的第几条命令
  }
  
  type GetReply struct {
  	Err   Err
  	Value string
  }
  ```

### client.go

> 客户端，用于向KVServer集群发送Get和Put请求

- `clerk`结构体

  ```go
  type Clerk struct {
  	servers []*labrpc.ClientEnd
  	// You will have to modify this struct.
  
  	OptionId int   // 客户端指令序号
  	ClientId int64 // 客户端 uuid
  	Leader   int   // 当前 leader 编号
  }
  ```

- `clerk`构造函数

  ```go
  func MakeClerk(servers []*labrpc.ClientEnd) *Clerk {
  	ck := new(Clerk)
  	ck.servers = servers
  
  	ck.Leader = 0
  	ck.ClientId = nrand()  // 随机uuid函数，源代码中有
  	ck.OptionId = 0
  	return ck
  }
  ```

- Get 请求

  ```go
  func (ck *Clerk) Get(key string) string {
  	DPrintf("触发Get\n")
      
      // 构造参数和返回值
  	args := &GetArgs{Key: key, ClientId: ck.ClientId, OptionId: ck.OptionId}
  	reply := &GetReply{}
      
      // 不断重试，知道成功
  	for {
  		ok := ck.servers[ck.Leader].Call("KVServer.Get", args, reply)
          
          // 目标服务器可能崩溃、网络波动或者不是Leader节点
          // 更换其他服务器
  		if !ok || reply.Err == ErrWrongLeader || reply.Err == ErrTimeOut {
  			ck.Leader = (ck.Leader + 1) % len(ck.servers)
  			reply.Err = ""
  		} else {
              // 成功，则指令Id增加
  			ck.OptionId++
  			break
  		}
  	}
      
      // 没有指定Key
  	if reply.Err == ErrNoKey {
  		return ""
  	}
  	return reply.Value
  }
  ```

- Put  Append 请求

  ```go
  func (ck *Clerk) PutAppend(key string, value string, op string) {
  	
  	args := &PutAppendArgs{Key: key, Value: value, Op: op, ClientId: ck.ClientId, OptionId: ck.OptionId}
  	reply := &PutAppendReply{}
      
      // 目标服务器可能崩溃、网络波动或者不是Leader节点
      // 更换其他服务器
  	for {
  		ok := ck.servers[ck.Leader].Call("KVServer."+op, args, reply)
  		if !ok || reply.Err == ErrWrongLeader || reply.Err == ErrTimeOut {
  			ck.Leader = (ck.Leader + 1) % len(ck.servers)
  			reply.Err = ""
  		} else {
  			// 成功，则指令Id增加
  			ck.OptionId++
  			break
  		}
  	}
  }
  
  func (ck *Clerk) Put(key string, value string) {
  	ck.PutAppend(key, value, "Put")
  }
  func (ck *Clerk) Append(key string, value string) {
  	ck.PutAppend(key, value, "Append")
  }
  ```

### server.go

- 定义OP 指令

  ```go
  type Op struct {
  	Key      string   // key值索引
  	Value    string	  // 对应的值
  	Option   string	  // 操作类型   Get  Put   Append
  	ClientId int64	  // 发送指令的客户端Id
  	OptionId int	  // 指令Id
  }
  ```

- 定义KVServer

  ```go
  type KVServer struct {
  	mu      sync.Mutex
  	me      int
  	rf      *raft.Raft
  	applyCh chan raft.ApplyMsg
  	dead    int32 // set by Kill()
  
  	maxraftstate int // 如果数据太多则进行快照
  
  
  	kvMap            map[string]string // 维护一个kvMap   即数据库
  	lastOptionId     map[int64]int     // 客户端最后一个指令操作的Id
  	executeChan      map[int]chan Op   // raft的操作通道
  	lastIncludeIndex int			   // 上一条指令所在的Log索引	
  }
  ```

- 判断是否重复指令的函数和获得对应LogIndex下的chan通道

  ```go
  func (kv *KVServer) IsDuplicateRequest(clientId int64, OptionId int) bool {
  
  	_, ok := kv.lastOptionId[clientId]
  	if ok {
          // 判断是否小于最近执行的指令id
  		return OptionId <= kv.lastOptionId[clientId]
  	}
  	return ok
  }
  
  func (kv *KVServer) GetChan(index int) chan Op {
  
      // index为该指令所在的log索引
  	ch, ok := kv.executeChan[index]
  	if !ok {
          // 如果没有则新建一个 op 的通道
  		kv.executeChan[index] = make(chan Op, 1)
  		ch = kv.executeChan[index]
  	}
  	log.Println("create chan index", index)
  	return ch
  }
  ```

- 生成快照函数

  ```go
  // 将kvMap和lastOptionIdMap的数据存下来形成快照
  func (kv *KVServer) PersistSnapshot() []byte {
  	w := new(bytes.Buffer)
  	e := labgob.NewEncoder(w)
  	e.Encode(kv.kvMap)
  	e.Encode(kv.lastOptionId)
  	SnapshotBytes := w.Bytes()
  	return SnapshotBytes
  }
  ```

- 读取快照

  ```go
  func (kv *KVServer) ReadSnapshot(data []byte) {
  	if data == nil || len(data) < 1 {
  		return
  	}
  
  	r := bytes.NewBuffer(data)
  	d := labgob.NewDecoder(r)
  
  	var kvMap map[string]string
  	var lastOptionId map[int64]int
      
      // 从快照中读取kvMap和lastOptionId
  	if d.Decode(&kvMap) != nil || d.Decode(&lastOptionId) != nil {
  		fmt.Println("read persist err")
  	} else {
  		kv.kvMap = kvMap
  		kv.lastOptionId = lastOptionId
  	}
  }
  ```

- 提交函数，又或者监听？做响应的函数

  ```go
  func (kv *KVServer) applier() {
      // 只要当前服务器没挂
  	for !kv.killed() {
  		select {
              
          // 监听raft的提交通道
  		case msg := <-kv.applyCh:
              // 合法就继续执行
  			if msg.CommandValid {
  				kv.mu.Lock()
                  
                  // 检测指令所在的Log索引是否小于已经执行过的日志索引
  				if msg.CommandIndex <= kv.lastIncludeIndex {
  					kv.mu.Unlock()
  					continue
  				}
                  
                  // 更新
  				kv.lastIncludeIndex = msg.CommandIndex
                  
                  // 获得指令
  				command := msg.Command.(Op)
  				DPrintf("%d server applyCh msg = %v\n", kv.me, msg)
                  
                  // 判断是否为更改操作(Put、Get) 且不为重复指令
  				if command.Option != "Get" && !kv.IsDuplicateRequest(command.ClientId, command.OptionId) {
  
                      // 执行指令
  					switch command.Option {
  
  					case "Append":
  						kv.kvMap[command.Key] += command.Value
  
  					case "Put":
  						kv.kvMap[command.Key] = command.Value
  					}
  
                      // 更新最新客户端执行指令Id
  					kv.lastOptionId[command.ClientId] = command.OptionId
  				}
                  
                  // 执行Get指令
  				if command.Option == "Get" {
  					command.Value = kv.kvMap[command.Key]
  					DPrintf("%d server applyCh msg = %v, value = %v\n", kv.me, msg, command.Value)
  				}
  
                  // 如果是身为Leader，则将指令响应回去，说明执行成功
  				if _, isLeader := kv.rf.GetState(); isLeader {
  					kv.GetChan(msg.CommandIndex) <- command
  				}
                  
                  // 判断raft的size是否过大，过大则进行快照压缩
  				if kv.maxraftstate != -1 && kv.rf.RaftStateSize() >= kv.maxraftstate {
  					DPrintf("%d server PersistSnapshot, index = %v\n", kv.me, msg.CommandIndex)
  					kv.rf.Snapshot(msg.CommandIndex, kv.PersistSnapshot())
  				}
  				kv.mu.Unlock()
  			}
  
              // 如果提交的是快照，则进行读取和更新
  			if msg.SnapshotValid {
  				kv.mu.Lock()
  				DPrintf("%d SnapshotValid: kv.lastIncludeIndex =%d, msg.SnapshotIndex=%d\n", kv.me, kv.lastIncludeIndex, msg.SnapshotIndex)
  				kv.ReadSnapshot(msg.Snapshot)
  				kv.lastIncludeIndex = msg.SnapshotIndex
  
  				kv.mu.Unlock()
  			}
  
  		}
  
  	}
  }
  ```

- KVServer的构造函数

  ```go
  func StartKVServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int) *KVServer {
  	// call labgob.Register on structures you want
  	// Go's RPC library to marshall/unmarshall.
  	labgob.Register(Op{})
  
  	kv := new(KVServer)
  	kv.me = me
  	kv.maxraftstate = maxraftstate
  
  
      // ch和rf初始化
  	kv.applyCh = make(chan raft.ApplyMsg)
  	kv.rf = raft.Make(servers, me, persister, kv.applyCh)
      
      // 集合初始化
  	kv.kvMap = make(map[string]string)
  	kv.executeChan = make(map[int]chan Op)
  	kv.lastOptionId = make(map[int64]int)
      
      // 初始值
  	kv.lastIncludeIndex = -1
      
      // 读取快照
  	snapshot := persister.ReadSnapshot()
  	kv.mu.Lock()
  	kv.ReadSnapshot(snapshot)
  	kv.mu.Unlock()
      
      // 创建提交监听线程
  	go kv.applier()
  
  	return kv
  }
  ```

- Get、Put、Append 请求处理

  ```go
  func (kv *KVServer) Get(args *GetArgs, reply *GetReply) {
      // 判断服务器是否还在
  	if kv.killed() {
  		reply.Err = ErrWrongLeader
  		return
  	}
  
  	// 构造操作指令
  	op := Op{Key: args.Key, Option: "Get", ClientId: args.ClientId, OptionId: args.OptionId}
      
      // 判断是否是Leader
      // 调用Start形成日志进入到Raft集群
  	index, _, isLeader := kv.rf.Start(op)
  	if !isLeader {
  		reply.Err = ErrWrongLeader
  		return
  	}
  	// 阻塞等待 - - 要设置超时时间
      // 等待Raft集群复制完Log且提交指令
  	kv.mu.Lock()
  	ch := kv.GetChan(index)
  	kv.mu.Unlock()
  	select {
      // 判断返回的是不是同一指令  不用Index是因为该位置的Log可能被更换
  	case result := <-ch:
  		if result.OptionId != args.OptionId || result.ClientId != args.ClientId {
  			reply.Err = ErrWrongLeader
  		} else {
  			reply.Value = result.Value
  			DPrintf("Key= %s Get value = %s\n", args.Key, result.Value)
  			reply.Err = OK
  		}
  
      // 超时处理
  	case <-time.After(100 * time.Millisecond):
  		DPrintf("Get Timeout\n")
  		reply.Err = ErrTimeOut
  	}
      
      // 释放通道资源
  	go func() {
  		kv.mu.Lock()
  		delete(kv.executeChan, index)
  		kv.mu.Unlock()
  	}()
  }
  
  func (kv *KVServer) PutAppend(args *PutAppendArgs, reply *PutAppendReply) {
  	// 判断服务器是否还在
  	if kv.killed() {
  		reply.Err = ErrWrongLeader
  		return
  	}
  
      // 构造操作指令
  	op := Op{Key: args.Key, Option: args.Op, ClientId: args.ClientId, OptionId: args.OptionId, Value: args.Value}
  
      // 判断是否是Leader
  	index, _, isLeader := kv.rf.Start(op)
  	if !isLeader {
  		reply.Err = ErrWrongLeader
  		return
  	}
      
      // 阻塞等待 - - 要设置超时时间
      // 等待Raft集群复制完Log且提交指令
  	kv.mu.Lock()
  	ch := kv.GetChan(index)
  	kv.mu.Unlock()
  	select {
      // 判断返回的是不是同一指令  不用Index是因为该位置的Log可能被更换
  	case result := <-ch:
  		if result.OptionId != args.OptionId || result.ClientId != args.ClientId {
  			DPrintf("ErrWrongLeader: result.OptionId =%d args.OptionId=%d result.ClientId=%d  args.ClientId=%d\n", result.OptionId, args.OptionId, result.ClientId, args.ClientId)
  			reply.Err = ErrWrongLeader
  		} else {
  			reply.Err = OK
  		}
  
      // 超时处理
  	case <-time.After(100 * time.Millisecond):
  		DPrintf("PutAppend Timeout\n")
  		reply.Err = ErrTimeOut
  	}
      
      // // 释放通道资源
  	go func() {
  		kv.mu.Lock()
  		DPrintf("%d delet chan: %d\n", kv.me, index)
  		delete(kv.executeChan, index)
  		kv.mu.Unlock()
  	}()
  
  }
  
  func (kv *KVServer) Put(args *PutAppendArgs, reply *PutAppendReply) {
  	// Your code here.
  	kv.PutAppend(args, reply)
  }
  
  func (kv *KVServer) Append(args *PutAppendArgs, reply *PutAppendReply) {
  	// Your code here.
  	kv.PutAppend(args, reply)
  }
  ```

  

# Frangipani

> 这个好像没有paper

## 基础概念

1. 所有用户都可以获得同一组文件的一致视图。
2. 可以轻松地将更多服务器添加到现有的Frangipani安装中，以增加其存储容量和吞吐量，而无需更改现有服务器的配置或中断其运行。服务器可以被看作是“砖块”，可以逐步堆叠起来，以根据需要构建尽可能大的文件系统。
3. 系统管理员可以添加新用户，而无需担心哪些计算机将管理其数据或哪些磁盘将存储数据。
4. 系统管理员可以对整个文件系统进行完整且一致的备份，而不会将其关闭。备份可以选择性地保持在线状态，使用户能够快速访问意外删除的文件。
5. 文件系统可以容忍计算机、网络和磁盘故障并从中恢复，而无需操作员干预。

![image-20240726215313420](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240726215313420.png)

- Frangipani的结构  （物理磁盘和虚拟磁盘）
- 日志
- 锁

## 视频

> 三个挑战

### 缓存一致性

- 锁

  ![image-20240727210032004](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240727210032004.png)

  工作台只有当持有锁的时候才会缓存文件

  ![image-20240727210344703](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240727210344703.png)

  锁的流程

  ![image-20240727211421986](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240727211421986.png)

  锁竞争过程

  **无论怎么样，工作站都会每隔30秒将本机的内容存入padle中，防止连带数据一块崩溃**

### 原子性

以事物的方式实现->以锁的方式实现，在一次操作中一次性获取所需要的所有锁，在事物完成之前都不会释放锁，这样其他工作台就不会看到这件事的存在

![image-20240727212303939](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240727212303939.png)

### 崩溃恢复

采用预写式日志的方式去处理，要处理一件事，先写日志再执行

Frangipani的日志是记录在padle中，而不是本地磁盘，防止某个工作台的某个指令因崩溃执行失败，padle可以将这个执行日志发送给其他工作台，让其完成这个指令

在对文件操作的过程中padle会对其增加版本号信息，防止在日志恢复的过程中对已修改的文件再次进行修改



# Distributed Transactions

> [论文部分：9.1.5,9.1.6,9.5.2,9.5.3](https://ocw.mit.edu/courses/res-6-004-principles-of-computer-system-design-an-introduction-spring-2009/de2b7c59e413f58e51eac60acd52efef_atomicity_open_5_0.pdf)
>
> 分布式事务，原子性操作和锁

## 基础概念

一个是事物

一个是锁

## 视频

### 并发控制

- **悲观方法**

  > 锁机制，对要操作的对象获取锁

  - 两阶段锁   第一阶段（获取锁）    第二阶段 （持有锁直到完成或者中断）
  - ![image-20240728135247725](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728135247725.png)
  - 完整的分布式事务流程
  - 使用log去防止崩溃   A或B在发送YES或NO之前先log在本地磁盘，   TC端在发送commit之前也先log在本地， 崩溃时方便恢复
  - ![image-20240728141523298](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728141523298.png)
  - 通过每个服务中集成Raft集群，提高容错率和高可用性

- **乐观方法**

  > 无需关心事务发生的情况，只有在最后的情况才去判断是否有其他事物影响

### 原子提交

# Spanner

> [paper链接](http://nil.csail.mit.edu/6.824/2020/papers/spanner.pdf)

## 基础概念

数据存储在架构化的半关系表中;数据是版本化的，每个版本都会自动带有其提交时间的时间戳;旧版本的数据受可配置的垃圾回收策略的约束;应用程序可以在旧时间戳读取数据。Spanner 支持通用事务，并提供基于 SQL 的查询语言。

Spanner是Google的可扩展、多版本、全球分布式、同步复制的数据库系统。它是第一个在全球范围内分布数据并支持外部一致性分布式事务的系统

![image-20240728172625366](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728172625366.png)

spanserver在框架中的位置

![image-20240728173155176](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728173155176.png)

spanserver的大体框架

**TrueTimeApi**

TrueTime API是Spanner实现外部一致性的关键组件。该API提供了一种全局同步的时间机制，允许Spanner为事务分配全局一致的时间戳。

TrueTime API通过使用多种现代时钟参考（如GPS和原子钟）来提供准确的时间。该API提供了两个主要功能：获取当前时间和获取时间的不确定性。

通过使用TrueTime API，Spanner能够确保所有事务的时间戳都是一致的，支持外部一致的读写操作和原子模式更新。

## 视频

![image-20240728201513073](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728201513073.png)

一个事务在spanner中的流程，通过事务协调者的复制，来解决两阶段提交因崩溃而导致的阻塞

![image-20240728204004842](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728204004842.png)

在执行只读的事务时，会在开始的时候记录一个时间戳（读写是在提交的时候），数据副本中的数据是带有时间戳的，在查询时，会返回最大且小于请求时间戳时的副本值。

spanner也具有同步时间的功能，是利用GPS的，在返回时间戳给的不是值，而是个取值范围(因为会有响应时间差)

![image-20240728214328448](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240728214328448.png)

对于事物1，已经准备好了，但不能立马提交，因为当前时间戳小于发送请求时间戳的Last值，循环等待超过时再继续执行

# FaRM  OCC

> Optimistic Concurrency Control
>
> [Paper链接](http://nil.csail.mit.edu/6.824/2020/papers/farm-2015.pdf)
>
> FaRM的主内存分布式计算平台可以提供具有严格序列化、高性能、持久性和高可用性的分布式事务

## 基础概念

- RDMA

  ![image-20240730092943079](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240730092943079.png)

  远程直接内存访问，该技术使得用户程序能够绕过操作系统内核及CPU，直接与网络接口卡（NIC）交互，实现网络通信。这种方式不仅大幅提升了通信带宽，还显著降低了网络延迟，优化了整体性能

- DRAM

  DRAM是Dynamic Random Access *Memory(动态随机存取存储器)的缩写,是最为常见的系统内存*

![image-20240730143727488](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240730143727488.png)

架构部分

- FaRM在非易失性DRAM中对数据和事务日志使用主备份复制，并使用直接与主备份通信的非复制事务协调器。
- 备份数据，事物处理，故障恢复（租聘的使用），支持事物的恢复

## 视频部分

- 非易失性的RAM

  通过一个大电池来链接所有RAM，一旦发生大范围停电，该电池续上撑住几分钟，在这几分钟内，所有RAM都将数据存储到硬盘中进行持久化保存数据，电恢复后再去读取数据到RAM中，保证了RAM的非易失性

- RDMA

  通过使用RDMA将一条消息绕过内核快速投递到其他节点程序的消息队列中，使其进行消费处理

- 事务处理

  ![image-20240730220226927](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240730220226927.png)

  **完整的事务流程**

  读取对象值 -> (只读事件无后续，后面的是写事件) 修改对象  -> 请求上锁  (若之前读取对象时还额外读一些没有改变的对象，则要将这些对象上交判断) -> 判断有无锁(判断那些只读对象有无上锁)  -> 争夺锁成功的话进行两阶段提交 ->  询问服务端是否准备好 -> 是则客户端进行提交 -> 服务端提交成功更改版本号进行响应 -> 客户端收到响应发送消息令服务端将此次事务的日志删除

  **以上的事务流程都是走了RDAM通道来进行实现的**

  高清图

  ![image-20240730220817211](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240730220817211.png)

## Lab 5  

> 实验概述   [链接](https://pdos.csail.mit.edu/6.824/labs/lab-shard.html)
>
> - ShardCtrler：负责管理集群配置，其中记录了每组ShardKVServer的集群信息和每个分片服务于哪组ShardKVServer。ShardCtrler也是由多个raft节点组成，所以是一个高可用的服务。
> - ShardKVServer：相比lab3的KVServer，新增了几个功能：1.要定时从ShardCtrler上拉取最新配置信息，只服务属于本集群的Key请求，拒绝服务属于其他集群的Key请求。2.支持配置更新，即当配置发生变化时，若不再属于本集群的Key，需要清除内容，回收空间。3.新增属于本集群的Key，需要从其他集群拉取该Key的内容，当拉取完毕后再对外提供正常服务。
> - Client：客户端定时从ShardCtrler上拉取最新配置信息，然后将Get/PutAppend请求分发到对应的ShardKVServer集群上。

![image-20240730161607694](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240730161607694.png)

### Part A  ShardCtrler

> 实现分片管理控制
>
> [参考文章](https://www.cnblogs.com/lawliet12/p/16972387.html)

![image-20240805090532171](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240805090532171.png)

- 实现的东西  （管理shard）
  - JOIN(加入一组新keys，平均分配Shards管理这部分keys)
  - MOV(将制定Shard分配管理指定keys)
  - Leave(移除指定keys组，将移除的shards平均分配给其他keys组)

**Code**

- 常数定义和打印函数

  ```go
  const (
  	T_Join  = "Join"
  	T_Leave = "Leave"
  	T_Move  = "Move"
  	T_Query = "Query"
  )
  
  type T_Op string   // 操作类型
  
  // 打印函数
  func DPrintf(format string, a ...interface{}) (n int, err error) {
  	if Debug {
  		log.Printf(format, a...)
  	}
  	return
  }
  
  type ShardClerk struct {
  	seqId       int     // 用于过滤重复的请求
  	msgUniqueId int     // 消息的唯一标识  日志索引
  	messageCh   chan Op // 用于通知消息处理完
  }
  ```

- 在common.go中的请求参数上增加版本号信息  （`SeqId`  `CkId`） 请求Id和ClerkId

  ```go
  type JoinArgs struct {
  	Servers map[int][]string // new GID -> servers mappings
  	SeqId   int
  	CkId    int64
  }
  type MoveArgs struct {
  	Shard int
  	GID   int
  	SeqId int
  	CkId  int64
  }
  type QueryArgs struct {
  	Num   int // desired config number
  	SeqId int
  	CkId  int64
  }
  ```

- 在client.go中，对Clerk增加ckId树形和seqId属性

  ```go
  type Clerk struct {
  	servers []*labrpc.ClientEnd
  	// Your data here.
  	ckId  int64
  	seqId int
  	mu    sync.Mutex
  }
  // 在makeClerk中初始化ckId
  ck.ckId = nrand()
  
  // 在发送请求时，需要在args中增加ckId和seqId
  // 记得加锁
  ck.mu.Lock()
  args.CkId = ck.ckId
  args.SeqId = ck.allocSeqId()  // 自增请求Id
  DPrintf("[Clerk-%d] call [Query], args=%v", ck.ckId, args)
  ck.mu.Unlock()
  ```
  
- 类的结构

  ```go
  // Shard 请求
  type ShardClerk struct {
  	seqId       int     // 用于过滤重复的请求
  	msgUniqueId int     // 消息的唯一标识  日志索引
  	messageCh   chan Op // 用于通知消息处理完
  }
  
  // Shard Controller
  type ShardCtrler struct {
  	mu      sync.Mutex
  	me      int
  	rf      *raft.Raft
  	applyCh chan raft.ApplyMsg
  
  	// Your data here.
  	requestMap map[int64]*ShardClerk // 过滤掉重复的请求  clientId -> *ShardClerk
  	configs    []Config              // indexed by config num
  }
  
  // 操作参数
  type Op struct {
  	// Your data here.
  	Command T_Op
  	SeqId   int
  	Servers map[int][]string // T_Join   要加入的组号和服务器数组(应该为空)
  	GIDs    []int            // T_Remove 要删除的组号数组
  	Shard   int              // T_Move 	 要移动的shard
  	GID     int              // T_Move   要移动到的组号
  	CkId    int64            // Clerk 的 Id
  }
  ```

- 对config里的组进行一些查询的函数

  ```go
  // 通过 clerkId 获取 最新的 ShardClerk   没有则新建
  func (sc *ShardCtrler) GetCk(ckId int64) *ShardClerk {
  	ck, found := sc.requestMap[ckId]
  	if !found {
  		ck = new(ShardClerk)
  		ck.messageCh = make(chan Op)
  		sc.requestMap[ckId] = ck
  		DPrintf("[ShardCtrler-%d] Init ck %d", sc.me, ckId)
  	}
  	return sc.requestMap[ckId]
  }
  
  // 获得组号数组
  func (sc *ShardCtrler) getGIDs() []int {
  	conf := sc.getConfig(-1)
  	gids := make([]int, 0)
  	for gid, _ := range conf.Groups {
  		gids = append(gids, gid)
  	}
  	sort.Ints(gids)   // 排序
  	return gids
  }
  
  // 获取组的shard编号数组
  func (sc *ShardCtrler) getGroupShards(gid int) []int {
  	conf := sc.getConfig(-1)
  	shards := make([]int, 0)
  	for shard, shardGid := range conf.Shards {
  		if gid == shardGid {
  			shards = append(shards, shard)
  		}
  	}
  	sort.Ints(shards)
  	return shards
  }
  
  // 获取配置 通过配置编号  -1的话就是获取到最新的
  func (sc *ShardCtrler) getConfig(confNumber int) Config {
  	if confNumber == -1 || confNumber >= len(sc.configs) {
  		return sc.configs[len(sc.configs)-1]
  	}
  	return sc.configs[confNumber]
  }
  ```

- Join  Leave  Move  Query 

  ```go
  // 四个相应请求处理方式一样，不同的地方是打印日志上的去呗以及对OP中的Command不同
  // 其他基本大致一样
  func (sc *ShardCtrler) Join(args *JoinArgs, reply *JoinReply) {
  	// Your code here.
      
      // 没事上把锁，保证安全哈哈
  	sc.mu.Lock()
  	DPrintf("[ShardCtrler-%d] Received Req [Join] args=%v", sc.me, args)
  
  	// 通过 Raft 算法进行一致性处理 让raft增加日志   Start
  	logIndex, _, isLeader := sc.rf.Start(Op{
  		Servers: args.Servers,
  		SeqId:   args.SeqId,
  		Command: T_Join,
  		CkId:    args.CkId,
  	})
  
  	// 如果不是leader，返回
  	if !isLeader {
  		reply.WrongLeader = true
  		DPrintf("[ShardCtrler-%d] Received Req [Join] args=%v, not leader, return", sc.me, args)
  		sc.mu.Unlock()
  		return
  	}
  
  	// 获取 ShardClerk
  	ck := sc.GetCk(args.CkId)
  	ck.msgUniqueId = logIndex
  
  	DPrintf("[ShardCtrler-%d] Wait Req [Join] args=%v, ck.msgUniqueId = %d", sc.me, args, ck.msgUniqueId)
  	sc.mu.Unlock()
  
  	// 上面raft已经增加了日志，等待消息处理完
  	_, WrongLeader := sc.WaitApplyMsgByCh(ck)
  	DPrintf("[ShardCtrler-%d] Wait Req [Join] Result=%v", sc.me, WrongLeader)
  
  	// 超时或者不是leader
  	reply.WrongLeader = WrongLeader
  }
  ```

- 对请求的流程间的消息处理

  ```go
  // 等待消息处理完后
  func (sc *ShardCtrler) WaitApplyMsgByCh(ck *ShardClerk) (Op, bool) {
  	startTerm, _ := sc.rf.GetState()
  	timer := time.NewTimer(120 * time.Millisecond)
  	for {
  		select {
  		case Msg := <-ck.messageCh:
  			return Msg, false
  		case <-timer.C:
  			curTerm, isLeader := sc.rf.GetState()
  			if curTerm != startTerm || !isLeader {
  				sc.mu.Lock()
  				ck.msgUniqueId = 0
  				sc.mu.Unlock()
  				return Op{}, true
  			}
  			timer.Reset(120 * time.Millisecond)
  		}
  	}
  }
  
  // 通知消息处理完
  func (sc *ShardCtrler) NotifyApplyMsgByCh(ch chan Op, Msg Op) {
  	// we wait 200ms
  	// if notify timeout, then we ignore, because client probably send request to anthor server
  	timer := time.NewTimer(120 * time.Millisecond)
  	select {
  	case ch <- Msg:
  		DPrintf("[ShardCtrler-%d] NotifyApplyMsgByCh finish , Msg=%v", sc.me, Msg)
  		return
  	case <-timer.C:
  		DPrintf("[ShardCtrler-%d] NotifyApplyMsgByCh Msg=%v, timeout", sc.me, Msg)
  		return
  	}
  }
  ```

- raft日志登记完后，通知server处理msg

  ```go
  // raft 日志登记完毕后，处理操作指令
  func (sc *ShardCtrler) processMsg() {
  	for {
  		applyMsg := <-sc.applyCh
  		opMsg := applyMsg.Command.(Op)
  		_, isLeader := sc.rf.GetState()
  		sc.mu.Lock()
  		ck := sc.GetCk(opMsg.CkId)
  		// already process
  		DPrintf("[ShardCtrler-%d] Received Msg %v, Isleader=%v", sc.me, applyMsg, isLeader)
  
  		// 如果是leader，且消息的唯一标识等于当前的日志索引，那么通知消息处理完
  		if applyMsg.CommandIndex == ck.msgUniqueId && isLeader {
  			DPrintf("[ShardCtrler-%d] Ready Notify To %d Msg %v, msgUniqueId=%d", sc.me, opMsg.CkId, applyMsg, ck.msgUniqueId)
  			sc.NotifyApplyMsgByCh(ck.messageCh, opMsg)
  			DPrintf("[ShardCtrler-%d] Notify To %d Msg %v finish ... ", sc.me, opMsg.CkId, applyMsg)
  			ck.msgUniqueId = 0
  		}
  
  		if opMsg.SeqId < ck.seqId {
  			DPrintf("[ShardCtrler-%d] already process Msg %v finish ... ", sc.me, applyMsg)
  			sc.mu.Unlock()
  			continue
  		}
  
  		ck.seqId = opMsg.SeqId + 1
  		sc.invokeMsg(opMsg)
  		sc.mu.Unlock()
  	}
  }
  ```

- 按照command处理msg

  ```go
  // 处理不同的操作指令
  func (sc *ShardCtrler) invokeMsg(Msg Op) {
  	DPrintf("[ShardCtrler-%d] Do %s, Msg=%v, configs=%v", sc.me, Msg.Command, Msg, sc.getConfig(-1))
  	switch Msg.Command {
  	// 根据指令去对组进行操作变换
  	case T_Join: // add a set of groups
  		latestConf := sc.getConfig(-1)
  		newGroups := make(map[int][]string)
  		// 将新的组加入到新的配置中
  		for gid, servers := range Msg.Servers {
  			newGroups[gid] = servers
  		}
  		// merge old group
  		for gid, servers := range latestConf.Groups {
  			newGroups[gid] = servers
  		}
  		// append new config
  		config := Config{
  			Num:    len(sc.configs),
  			Groups: newGroups,
  			Shards: latestConf.Shards,
  		}
  		sc.configs = append(sc.configs, config)
  		// 新的组里的shard可能或多或少，需要重新平衡
  		sc.rebalance()
  	case T_Leave: // delete a set of groups
  		latestConf := sc.getConfig(-1)
  		newGroups := make(map[int][]string)
  		for gid, servers := range latestConf.Groups {
  			// 不在删除的组里 则加入到新的组里
  			if !xIsInGroup(gid, Msg.GIDs) {
  				newGroups[gid] = servers
  			}
  		}
  		// 设置新的配置
  		config := Config{
  			Num:    len(sc.configs),
  			Groups: newGroups,
  			Shards: latestConf.Shards,
  		}
  		sc.configs = append(sc.configs, config)
  		sc.rebalance()
  	case T_Move:
  		latestConf := sc.getConfig(-1)
  		config := Config{
  			Num:    len(sc.configs),
  			Groups: latestConf.Groups,
  			Shards: latestConf.Shards,
  		}
  		config.Shards[Msg.Shard] = Msg.GID // 不需要重新平衡
  		sc.configs = append(sc.configs, config)
  	case T_Query:
  		// nothing to do
  	default:
  		DPrintf("[ShardCtrler-%d] Do Op Error, not found type, Msg=%v", sc.me, Msg)
  	}
  }
  ```

- 重新均匀分配shards

  ```go
  // 收集空闲分片和低于平均数量的组号
  func (sc *ShardCtrler) collectRichShardsAndPoorGroups(gids []int, avgShard int) ([]int, map[int]int) {
  	richShards := make([]int, 0)
  	poorGroups := make(map[int]int)
  	for _, gid := range gids {
  
  		// 该组的shards
  		groupShards := sc.getGroupShards(gid)
  		DPrintf("[ShardCtrler-%d] rebalance groupShards=%v, avgShard=%d, gids=%v", sc.me, groupShards, avgShard, gids)
  		overShards := len(groupShards) - avgShard
  		for i := 0; i < overShards; i++ {
  			richShards = append(richShards, groupShards[i])
  		}
  
  		// 如果该组的shard小于平均值，则加入到贫穷的组中
  		if overShards < 0 {
  			poorGroups[gid] = len(groupShards)
  		}
  	}
  	return richShards, poorGroups
  }
  
  func (sc *ShardCtrler) rebalance() {
  	// 获得最新的配置
  	latestConf := sc.getConfig(-1)
  	// 如果所有组都离开了，则将shard重置为0
  	if len(latestConf.Groups) == 0 {
  		for index, _ := range latestConf.Shards {
  			latestConf.Shards[index] = InvalidGroup
  		}
  		DPrintf("[ShardCtrler-%d] not groups, rebalance result=%v, sc.config=%v", sc.me, latestConf.Shards, sc.configs)
  		return
  	}
  
  	// 组号的列表数组
  	gids := sc.getGIDs()
  
  	// 空闲的shard
  	idleShards := make([]int, 0)
  	// 首先遍历一遍，找到空闲的shard
  	for index, belongGroup := range latestConf.Shards {
  		// 如果不属于任何组，且所属组号不在管理的组号数组中(处理Leave的)，则加入到空闲的shard中
  		if belongGroup == InvalidGroup || !xIsInGroup(belongGroup, gids) {
  			idleShards = append(idleShards, index)
  		}
  	}
  	// 第二次遍历，找到富裕的shard和贫穷的组
  	// 平均每个组应该有多少个shard
  	avgShard := (len(latestConf.Shards) / len(gids))
  	richShards, poorGroups := sc.collectRichShardsAndPoorGroups(gids, avgShard)
  	DPrintf("[ShardCtrler-%d] rebalance avgShard=%d idleShards=%v, richShards=%v, poorGroups=%v latestConf=%v", sc.me, avgShard, idleShards, richShards, poorGroups, latestConf)
  
  	// 将富裕的shard归类为空闲shard
  	idleShards = append(idleShards, richShards...)
  	sort.Ints(idleShards)
  	allocIndex, i := 0, 0
  
  	// 获得贫穷的组号数组
  	poorGIDs := make([]int, 0)
  	for gid := range poorGroups {
  		poorGIDs = append(poorGIDs, gid)
  	}
  	sort.Ints(poorGIDs)
  
  	// 遍历贫穷的组，将空闲的shard分配给贫穷的组
  	for _, gid := range poorGIDs {
  
  		// 该组的shard当前数量
  		groupShardsNum := poorGroups[gid]
  		for i = allocIndex; i < len(idleShards); i++ {
  			groupShardsNum += 1
  			// 将空闲的shard分配给贫穷的组
  			latestConf.Shards[idleShards[i]] = gid
  
  			// 如果该组的shard数量大于平均值，则跳出循环
  			if groupShardsNum > avgShard {
  				break
  			}
  		}
  
  		// 更新分配的起始索引
  		allocIndex = i
  	}
  	// 处理剩余的空闲shard
  	// 一个一个的分配给组
  	for ; allocIndex < len(idleShards); allocIndex++ {
  		i = allocIndex % len(gids)
  		latestConf.Shards[idleShards[allocIndex]] = gids[i]
  	}
  
  	// 更新最新的配置
  	sc.configs[len(sc.configs)-1] = latestConf
  	DPrintf("[ShardCtrler-%d] rebalance result=%v, sc.config=%v", sc.me, latestConf.Shards, sc.getConfig(-1))
  }
  
  ```

### Part B ShardKV

- gorouten 循环Query配置的变更

  ```mermaid
  graph TD
  A[begin]-->|发起Query请求|B(IsLeader)
  B -->|是| C(QueryConfig)
  C -->|判断是否为最初config| D(ConfigNum == 1)
  D -->|是| E(Raft.Start执行ShardInit)
  E --> B
  D -->|否| F(检查新增Shard和删除Shard)
  F -->|否| G(Raft.Start修改ShardContainer.ConfigNum)
  G --> B
  F -->|是| H(Raft.Start同步修改 TransferShards和WaitJoinShards)
  H --> B
  ```

- 切片迁移流程

  ```mermaid
  graph LR
  A[ShardKV]-->|1. Query Config|B(ShardCtrler)
  A -->|2.StartShardChangeCommand| C(Raft)
  C -->|3.ShardChangeCommandReturn| A
  A -->|8.StartShardLeaveCommand| C
  A -->|4.SendRequestMoveShard| D(ShardKV)
  D -->|7.ReplyRequestMoveShard| A
  D -->|5.StartShardJoinCommand| F(Raft)
  F -->|6.ShardJoinCommandReturn| D
  ```

  后面有点看不下去了哈哈哈哈

# Big-Data  Spark

> [Paper链接](http://nil.csail.mit.edu/6.824/2020/papers/zaharia-spark.pdf)
>
> Spark是一个实现了RDD(Resilient Distributed Datasets  弹性分布数据库)的系统
>
> 不同于MapReduce等将中间数据写入外部稳定文件系统，RDD将中间结果持久化到内存中，控制它们的分区以优化数据放置，并使用一组丰富的操作符来操作它们。
>
> 如果RDD的分区丢失，RDD有足够的信息来重新计算它是如何从其他RDD派生的，这是RDD的容错方式，以算力换时间，因此，丢失的数据可以恢复，通常非常快，而不需要昂贵的复制。

## 基础概念

- RDD，数据分区

- Spark对RDD的使用，操作数据集，对数据集进行分析，有点像Hadoop，但是速度比Hadoop快

  ![image-20240731090827778](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240731090827778.png)

- ![image-20240731125428145](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240731125428145.png)

  spark驱动程序架构

- RDD最适合于对数据集的所有元素应用相同操作的批处理应用程序。DD不太适合对共享状态进行异步细粒度更新的应用程序，例如Web应用程序的存储系统或增量Web爬虫。

- RDD在Spark中的API

  ![image-20240731130505068](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240731130505068.png)

- 具有检查点的功能，方便恢复，可以通过RDD去将输入转为对象编程语言

## 视频部分

- [前面一部分代码研读的参考博客](https://blog.csdn.net/qq_40229166/article/details/129818190)				![image-20240731213158455](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240731213158455.png)

这边每个Worker只读自己需要读的分区以及map操作，这一段自己干自己的事称之为“窄依赖”，后面distinct需要进行Worker间的通信，称之为“宽依赖”，G.B.K，合并相同的key，spark肯能已经通过图猜到，所以前面shuffle已经是用key去进行分区，所以后面就以“窄”依赖进行操作了(直接竖下来)

- 宽依赖和窄依赖

![什么是宽依赖什么是窄依赖](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/20230512174930175.png)

- Spark对于容错的机制，是在图中的一些节点中设置检查点，当机器重启时，从检查点重新进行计算，一般设置在宽依赖后(因为这个涉及到多个Worker)

# Memcache at Facebook

> [paper链接](https://pdos.csail.mit.edu/6.824/papers/memcache-fb.pdf)
>
> Facebook中的缓存应用，分布式键值存储

## 基础概念

- 对于读的请求使用的是UDP（省去链接的时间），对于写的请求使用的TCP（省去重试的时间）
- 对于同时到达的秘钥请求，采用滑动窗口来进行削峰
- 对于一下子的大量请求对于一个值，Memcache采用租聘（带期限的锁）来进行控制，第一个获得锁的可以进行更改，后面的往后稍稍
- 池技术，分为两个池，小型池（针对于频繁缓存命中失败，租聘时间很短），大型池子（长时间不访问的）
- 对于更改次数多的，复制多个相同的值，每个值配一个秘钥
- Gutter 使用与Memcache服务突然爆费的临时替代品，占整个集群的百分5左右
- 冷集群预热，用于更换集群时，从热集群（当前集群）获得缓存值，而不是从数据库中获得
- 发送一个涉及到删除数据的sql时，数据库端会创建守护线程去监听，删除完后，广播给Memcache集群
- 对于大量请求，也具有负载均衡的功能

## 视频部分



#  Causal Consistency  COPS

> [Paper链接](http://nil.csail.mit.edu/6.824/2020/papers/cops.pdf)
>
> Causal Consistency  因果一致性
>
> COPS中的核心方法是在暴露写入之前跟踪并显式检查本地集群中是否满足键之间的因果依赖关系

## 基础概念

- COPS系统目标是实现**ALPS** A是Available，可用性； L是Low latency，低延迟；P是Partition-tolerance，分区容错；S是 high Scalability，高可伸缩性

- 对于处理写入冲突，COPS的方案是采用`the last-writer-wins rule` 最后写入的胜出（比较版本号）

  ![image-20240802164247955](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240802164247955.png)

- 一致性强度排序

- COPS是一个键值存储系统，设计用于在少量数据中心上运行，如图4所示。每个数据中心都有一个本地COPS集群，其中包含存储数据的完整副本。COPS的客户端是一个应用程序，它使用COPS客户端库直接调用COPS键值存储。客户端只与运行在同一数据中心的本地COPS集群通信。

  ![image-20240802165751688](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240802165751688.png)

- COPS的基本构建块是键值存储，在存储的时候还会额外携带一个版本号的记录方便实现`causal+`

- 在本地存储完数据后，将数据发送往不同集群的等效节点上

- 垃圾回收机制，通过设置秘钥过期时间，空间大小参数来进行空间释放

- COPS更多关心dep(依赖)关系，在处理事务的时候使用锁、


## 视频部分

# Certificate Transparency

> 证书透明性
>
> [文档链接](https://research.swtch.com/tlog)

## 基础概念

- 证书认证的过程，gmail.com服务器有着一个私钥，CA(证书认证机构)为其颁发一个包含名称公钥的证书，当客户端浏览器链接到gmail.com时，gmail.com会向客户端发送该证书，浏览器再将一个数据发送过去，如果该gmail.com用私钥加密后发送给客户端，客户端可以用证书中的公钥解析出原来数据就证明了身份
- ![image-20240803201825983](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240803201825983.png)
- 颁发的证书一般要放在一个证书管理服务器中，这个服务器里有对应的证书日志，证书归属者可以监控这个日志，使用merkle tree去存储，有点像二叉树，一层层上去算Hash值，通过这个Hash值去判断这个日志Hash是否包含于最新的Hash，也有个Gossip去共存一些大家都承认的证书，有异常的STH（sign tree head），会很快被发现 

# Bitcoin

> 点对点的电子现金系统
>
> [paper链接](http://nil.csail.mit.edu/6.824/2020/papers/bitcoin.pdf)
>
> 

## 基础概念

- ![image-20240804105203299](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240804105203299.png)

  加密过程：用下一个的公钥和上一个的签名进行Hash运算得到自己的签名

- proof of work

  工作量证明，每个区块有一个随机数，随机数计算完Hash后如果前导零数量合格，则挖矿成功，代表新的区块产生，前导零的数量随着新区块产生速率的增加而增加，起到调节作用

- ![image-20240804164207923](E:/java/note/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.assets/image-20240804164207923.png)防止双重支付的策略是，若同时有两个合法的区块产生，则暂时允许存在，随着后面新区块的增加，后续增加的区块会选择更长的那一条区块链，从而避免的双重支付
- 防止攻击策略，因为一个人拥有的CPU算力无法与现今以被承认允许的整个集群算力进行匹配，所以产生新区块的速度不可能超过，所以所在的恶意链中不可能是最长的

# BlockStack

> [paper链接](http://nil.csail.mit.edu/6.824/2020/papers/blockstack-2017.pdf)
>
> 区块链

# 总结

#### 首先是接触**MapReduce**，这个是将一个大型任务进行拆分给不同的Worker执行

- Map过程是将读取内容分拣出来到中间输出文件，随后的Reduce任务则将中间输出文件再进行处理，可以不断叠加中间的过程，从而达到目标的效果
- 其中的容错机制有超时重试（会设置任务开始的时间戳，循环判断当前时间戳与开始时的间隔是否超时）
- 实验一的内容就是将分别读取不同的文件，按生成的HashKey分配到不同的中间输出文件，随后每个Worker按照Reduce的方法处理分配到自己指定HashKey的中间输出文件

#### 随后了解了Google的文件系统**GFS**

- GFS的文件系统由多个节点组成，一个主节点和多个块(副本)节点，客户端查询文件时，根据文件名和偏移量(文件大小)去找到对应的块节点，再从该节点获取数据，减少主节点的负担
- 在容灾方面，GFS会进行副本的备份，在修改时，会先修改一个副本的数据，并令其为主副本，获得lease租约，在租约期内，将修改的内容按生成的序列号顺序同步到二级副本中，每成功同步一次就会延长租约时间，主节点在删除文件时会删除对应的租约
- 在恢复数据上，GFS有CheckPoints(Snapshot快照) 和日志文件，Checkpoints是在日志文件过大是生成的，恢复数据时，只要读取该checkPoints和执行剩余的日志指令即可，这个也是大部分分布式存储的日志处理方案
- 当进行删除文件时，并不会立马删除，而是会设置一个带时间戳的名字，当进行chunk级别的垃圾回收时，会对这些文件进行超时判断，时间一到，删除拜拜
- 每个节点都有个checkSum，是通过节点数据计算出来的一个校验数据，会定期校验checkSum来检查存放的数据是否损坏，一旦发现数据损坏，master 可以创建新的正确副本并删除损坏的副本，避免非活动的损坏 chunk 误导 master，使其认为副本数量足够

#### 接着就是大名鼎鼎的Raft协议了哈哈

- Raft是一种管理日志的共识算法，即达成共识的过程,而非一致性算法。一致性(consistency)是终态,共识算法是达成一致性的一种实现手段和过程。
- Raft 通过首先选举一位杰出的领导者，然后让领导者完全负责管理复制的日志来实现共识。领导者接受来自客户端的日志条目，将它们复制到其他服务器上，并告诉服务器何时可以安全地将日志条目应用于其状态机(提交)。
- 当从节点长时间未收到心跳请求，则会将任期+1并发起新一轮的选举，收到选举请求的节点会先判断该候选者的节点的任期是否大于自身，若大于，则更新自身任期，接着判断是否能投票给该候选者，检查最后日志的任期是否大于自身，若大于，则投票给该候选者，等于的话判断日志长度是否大于等于自身，若符合，给予投票，否则拒绝投票给该候选节点
- 若某日志已复制到大部分节点上，但未提交，主节点挂了，新主节点诞生，并接受新的日志，旧日志会和新日志一起提交
- 若主节点一下子接收到多个请求，且宕机了，若此时主节点更换并接受了新的请求，则曾经的主节点未复制到其他节点的日志会被抛弃，若在新日志到达前，又变回主节点，则会保留这些日志，并将这些日志复制到其他节点上
- 还有日志压缩，将已提交的日志压缩成快照(存储当前状态)，记录快照截至的日志索引，方便后续判断

#### 后面几个系统？框架？先来个Zookeeper

- zookeeper对比于redis使用类文件名系统储存数据模型
- zookeeper的锁机制是对该文件下子目录按顺序增加编号，如果最前面的编号是自己，就可以获得这个文件(数据)的锁，如果最前面的不是自己的编号，则监听前一个编号的文件(Watch)，当前一个编号的文件删除了之后就会通知自己去进行获得锁，这样子有效地避免了羊群效应->值一下子有太多请求申请获得锁，但只能获得一个，那剩余的请求又会不断重试，耗费大量的网络资源。
- zookeeper的双屏障机制，当进入zNode的数量达到一定时，才会一起执行计算，全都计算完后，才释放屏障

#### DynamoDb

- 与MongoDb类似，都是以集合来管理存储数据，有个主键，存储的时候设置，具有ACID
- CAP，Consistency一致性，Availability可用性，Partition tolerance分区容错性
- 强一致性，保证R+W=N+1，这样两者区域至少有一个重叠，写的时候只要有w个响应几个，读的时候读r个，这样就能保证并从中找到版本号最大的数据

#### Frangipani

- 一个运用了Raft的存储系统
- Frangipani程序里有个petal驱动，该驱动连着本地的磁盘或者远程磁盘，每个petal对应的有存储区域和锁服务器，当有多个Frangipani要对同一个数据进行更改时，会向锁服务器(Lock Server)请求对应的锁，持有锁的时候才会缓存数据
- 当有另一个客户端索求锁的时候，会通知持有锁的一方处理好数据，将数据存回远程磁盘中，并归还锁
- 不论有无抢夺锁，Frangipani都会隔一段时间将数据同步到petal中(30秒)，防止连带数据一起崩溃
- 在防止崩溃上，采用预写日志，先写日志再执行任务，并且日志时寄存再petal中，若执行失败，有petal将日志发给其他Frangipani执行
- 以事物的方式实现->以锁的方式实现原子性，在一次操作中一次性获取所需要的所有锁，在事物完成之前都不会释放锁，这样其他工作台就不会看到这件事的存在

#### 了解了分布式事务

- 采用锁去进行并发控制，获得锁，然后去进行两阶段提交
- 2PC(process commit)，两阶段提交，先询问服务器是否准备好了，客户端收到ok后才去commit，服务器收到commit后，才去释放锁，并返回ack确认
- 使用log去防止崩溃   A或B在发送YES或NO之前先log在本地磁盘，   TC端在发送commit之前也先log在本地， 崩溃时方便恢复
- 在每个服务中都去集成raft集群，确保可靠性

#### 了解了Spanner数据库

- Spanner是Google的可扩展、多版本、全球分布式、同步复制的数据库系统。它是第一个在全球范围内分布数据并支持外部一致性分布式事务的系统
- 当在写数据的时候，先写入一个数据库，该数据库再去向其他数据库进行两阶段提交复制数据
- 在执行只读的事务时，会在开始的时候记录一个时间戳（读写是在提交的时候），数据副本中的数据是带有时间戳的，在查询时，会返回最大且小于请求时间戳时的副本值。
- 当执行写的事务时，回去比较时间戳，只有当时间合适的时候才回去执行提交，与只读进行配合
- 利用的时间同步系统TrueTimeApi，返回的是时间的范围，而不是准确的值

#### 然后是FaRM

- 采用的时RDAM，远程直连RAM，绕过CPU直接访问RAM，将消息投递到应用程序的消息队列中，大大加快的访问速度，减轻CPU负担

- 非易失性的RAM，是指有备份电源，能够支撑断电的时候存储完数据再关机

- 完整的事务流程如下

  读取对象值 -> (只读事件无后续，后面的是写事件) 修改对象  -> 请求上锁  (若之前读取对象时还额外读一些没有改变的对象，则要将这些对象上交判断) -> 判断有无锁(判断那些只读对象有无上锁)  -> 争夺锁成功的话进行两阶段提交 ->  询问服务端是否准备好 -> 是则客户端进行提交 -> 服务端提交成功更改版本号进行响应 -> 客户端收到响应发送消息令服务端将此次事务的日志删除

#### Spark

- 感觉像是MapReduce的升级版哈哈
- 分布式的计算系统，将大型计算任务交给不同服务器去计算，最后将计算结果返回统计
- 这边每个Worker只读自己需要读的分区以及map操作，这一段自己干自己的事称之为“窄依赖”，后面distinct需要进行Worker间的通信，称之为“宽依赖”，G.B.K，合并相同的key，spark肯能已经通过图猜到，所以前面shuffle已经是用key去进行分区，所以后面就以“窄”依赖进行操作了(直接竖下来)

- Spark对于容错的机制，是在图中的一些节点中设置检查点，当机器重启时，从检查点重新进行计算，一般设置在宽依赖后(因为这个涉及到多个Worker)

#### COPS

- 因果一致性
- 因果一致性回去记录操作的依赖关系，比如KeyA依赖与KeyB的操作，会等KeyB操作完再去通知KeyA进行下一步的操作
